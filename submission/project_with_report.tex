\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{CITS3401 - Data Warehousing - Project 2: Pattern Discovery and Building Predictive Models of Mobile Phone Price}
    
    
    
    \author{Max Matthews (21506225), Frinze Erin Lapuz (22711649)}
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    Author: Max Matthews and Frinze Erin Lapuz (22711649)

This is the IPython Jupyter Notebook for generating the PDF report,
documentation, and generating the staging\_data.

To generate html, pdf and tex file, run the following command
\texttt{generate\_report.bat} in the command line. You may need to have
Anaconda activated, Jupyter NBconvert, and LaTex renderer (eg. MikTex)
in your environment to do this.

    \hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

For this project, we would like to use the mobile price classification
dataset as the source of data. The target of this project is to predict
whether the price of a mobile phone is high or not.

    \hypertarget{tasks-and-scope}{%
\subsection{Tasks and Scope}\label{tasks-and-scope}}

\hypertarget{data-cleaning-and-analysis}{%
\subsubsection{1) Data cleaning and
analysis}\label{data-cleaning-and-analysis}}

\begin{itemize}
\tightlist
\item
  Read through the table and the table column descriptions. Understand
  the meaning of each column in the table.
\item
  Distinguish the type of each attribute (e.g., nominal/categorical,
  numerical). You may need to discretise some attributes, when
  completing Task 2, 3 or 4.
\item
  Determine whether an attribute is relevant to your target variable.
  You may remove some attributes if they are not helpful for Task 2, 3,
  or 4. You might create separate data files for Task 2, 3 and 4.
\item
  Identify inconsistent data and take actions using the knowledge you
  have learnt in this unit.
\end{itemize}

\hypertarget{association-rule-mining}{%
\subsubsection{2) Association rule
mining}\label{association-rule-mining}}

\begin{itemize}
\tightlist
\item
  Select a subset of the attributes (or all the attributes) to mine
  interesting patterns. To rank the degree of interesting of the rules
  extracted, use support, confidence and lift.
\item
  Explain the top k rules (according to lift or confidence) that have
  the ``price\_category'' on the right-hand-side, where k \textgreater=
  1.
\item
  Explain the meaning of the k rules in plain English.
\item
  Given the rules, what recommendation will you give to a company
  willing to design a high price mobile phone (e.g., should the mobile
  phone equipped with bluetooth)?
\end{itemize}

\hypertarget{classification}{%
\subsubsection{3) Classification}\label{classification}}

\begin{itemize}
\tightlist
\item
  Use the ``price\_category'' as the target variable and train two
  classifiers based on different machine learning algorithms
  (e.g.~classifier 1 based on a decision tree; classifier 2 based on
  SVMs).
\item
  Evaluate the classifiers based on some evaluation metrics (e.g.,
  accuracy). You may use 10-fold cross-validation for the evaluation.
\end{itemize}

\hypertarget{clustering}{%
\subsubsection{4) Clustering}\label{clustering}}

\begin{itemize}
\tightlist
\item
  Run a clustering algorithm of your choice and explain how the results
  can be interpreted with respect to the target variable.
\end{itemize}

\hypertarget{data-reduction}{%
\subsubsection{5) Data reduction}\label{data-reduction}}

\begin{itemize}
\tightlist
\item
  Perform numerosity reduction and perform attribute reduction.
\item
  Train the two classifiers in Task 3 on the reduced data.
\item
  Answer the question: ``Does data reduction improve the quality of the
  classifiers''?
\end{itemize}

\hypertarget{attribute-selection}{%
\subsubsection{6) Attribute selection}\label{attribute-selection}}

\begin{itemize}
\tightlist
\item
  Select the top-10 most important attributes manually based on your
  understanding of the problem; select the top-10 most important
  attributes based on Information Gain.
\item
  Which attribute selection method is better and why?
\end{itemize}

\hypertarget{marking-scheme}{%
\subsection{\texorpdfstring{\textbf{Marking
Scheme}}{Marking Scheme}}\label{marking-scheme}}

{[}5 marks{]} Explain the data processing operations (e.g., remove some
attributes and action on inconsistent data) that you have done.

{[}5 marks{]} Explain and interpret the top k association rules mined;
based on the association rules, provide a recommendation for a company
willing to design a high price mobile phone.

{[}5 marks{]} Explain how you train the classifiers and your evaluation
results.

{[}5 marks{]} Clustering and interpretation of the clustering result
(with respect to the target variable).

{[}5 marks{]} Explain the data reduction you have performed; compare the
classifiers trained on reduced data with the classifiers trained on the
original data.

{[}5 marks{]} Your answer to Task 6.

    \hypertarget{tools-libraries-and-packages}{%
\subsection{Tools, Libraries and
Packages}\label{tools-libraries-and-packages}}

Python - Used throughout the project for data cleaning, data processing,
and modelling.

\hypertarget{imports}{%
\subsubsection{Imports}\label{imports}}

    https://graphviz.org/download/

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{pip} \PY{n}{install} \PY{n}{pandas}\PY{o}{\PYZhy{}}\PY{n}{profiling}\PY{p}{[}\PY{n}{notebook}\PY{p}{]} \PY{n}{mlxtend} \PY{n}{clusteval} \PY{n}{pca} \PY{n}{graphviz} \PY{n}{dtreeviz} \PY{n}{tabulate} \PY{o}{\PYZhy{}}\PY{o}{\PYZhy{}}\PY{n}{user}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Data analysis, manipulation, and profiling}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
\PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}colwidth} \PY{o}{=} \PY{l+m+mi}{100}
\PY{n}{pd}\PY{o}{.}\PY{n}{set\PYZus{}option}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{display.notebook\PYZus{}repr\PYZus{}html}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{k+kc}{False}\PY{p}{)}

\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{from} \PY{n+nn}{pandas\PYZus{}profiling} \PY{k+kn}{import} \PY{n}{ProfileReport}

\PY{c+c1}{\PYZsh{} Visualization}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
\PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}style}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{darkgrid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{axes.facecolor}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{.9}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Association Rule Mining}
\PY{k+kn}{from} \PY{n+nn}{mlxtend}\PY{n+nn}{.}\PY{n+nn}{frequent\PYZus{}patterns} \PY{k+kn}{import} \PY{n}{apriori}\PY{p}{,} \PY{n}{association\PYZus{}rules}

\PY{c+c1}{\PYZsh{} Training Setups}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{pipeline} \PY{k+kn}{import} \PY{n}{Pipeline}

\PY{c+c1}{\PYZsh{} Preprocessings and Attribute Selections}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{impute} \PY{k+kn}{import} \PY{n}{SimpleImputer}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{StandardScaler}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{decomposition} \PY{k+kn}{import} \PY{n}{PCA}
\PY{c+c1}{\PYZsh{} selection of best attributes from by default using f\PYZhy{}score https://scikit\PYZhy{}learn.org/stable/modules/generated/sklearn.feature\PYZus{}selection.f\PYZus{}classif.html}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{feature\PYZus{}selection} \PY{k+kn}{import} \PY{n}{SelectKBest}\PY{p}{,} \PY{n}{mutual\PYZus{}info\PYZus{}classif}\PY{p}{,} \PY{n}{f\PYZus{}classif}

\PY{c+c1}{\PYZsh{} Classifiers}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k+kn}{import} \PY{n}{DecisionTreeClassifier}\PY{p}{,} \PY{n}{plot\PYZus{}tree}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k+kn}{import} \PY{n}{SVC} \PY{c+c1}{\PYZsh{} Support Vector Machine Classifier}
\PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{tree}
\PY{k+kn}{import} \PY{n+nn}{graphviz}
\PY{k+kn}{from} \PY{n+nn}{dtreeviz}\PY{n+nn}{.}\PY{n+nn}{trees} \PY{k+kn}{import} \PY{n}{dtreeviz} 

\PY{n}{RANDOM\PYZus{}STATE} \PY{o}{=} \PY{l+m+mi}{1} \PY{c+c1}{\PYZsh{} Used as a seed value}
\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION} \PY{o}{=} \PY{l+m+mi}{10}
\PY{n}{NUMBER\PYZus{}OF\PYZus{}BEST\PYZus{}HYPER\PYZus{}PARAMS\PYZus{}TO\PYZus{}SHOW} \PY{o}{=} \PY{l+m+mi}{5}

\PY{c+c1}{\PYZsh{} Optimisation}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{GridSearchCV} \PY{c+c1}{\PYZsh{} tuning the model}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{,} \PY{n}{cross\PYZus{}validate}

\PY{c+c1}{\PYZsh{} Clustering}
\PY{k+kn}{from} \PY{n+nn}{clusteval} \PY{k+kn}{import} \PY{n}{clusteval}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{MinMaxScaler}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{cluster} \PY{k+kn}{import} \PY{n}{KMeans}\PY{p}{,} \PY{n}{AgglomerativeClustering}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{cluster} \PY{k+kn}{import} \PY{n}{hierarchy}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{cluster}\PY{n+nn}{.}\PY{n+nn}{hierarchy} \PY{k+kn}{import} \PY{n}{dendrogram}

\PY{c+c1}{\PYZsh{} Data Reduction}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k+kn}{import} \PY{n}{IsolationForest}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k+kn}{import} \PY{n}{OneClassSVM}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{covariance} \PY{k+kn}{import} \PY{n}{EllipticEnvelope}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{cluster} \PY{k+kn}{import} \PY{n}{DBSCAN}
\PY{k+kn}{from} \PY{n+nn}{pca} \PY{k+kn}{import} \PY{n}{pca}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k+kn}{import} \PY{n}{Markdown}\PY{p}{,} \PY{n}{display}
\PY{k}{def} \PY{n+nf}{display\PYZus{}markdown}\PY{p}{(}\PY{n}{dataframe}\PY{p}{)}\PY{p}{:}
    \PY{n}{display}\PY{p}{(}\PY{n}{Markdown}\PY{p}{(}\PY{n}{dataframe}\PY{o}{.}\PY{n}{to\PYZus{}markdown}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    

    \hypertarget{data-cleaning-and-profiling}{%
\section{Data Cleaning and
Profiling}\label{data-cleaning-and-profiling}}

There are many ways to approach a project's data cleaning, and data
profiling steps. For these processes (in Project 2) we will be using an
IPython Notebook, for the following reasons:

\begin{itemize}
\tightlist
\item
  Both group members are proficient in Python;
\item
  The report can be integrated with code for specific sections of the
  analysis;
\item
  The processes / procedures are highly repeatable and easily automated
  using scripts;
\item
  Data exploration and anomaly detection can easily be performed through
  a variety of visualizations (charts, graphs, tables, etc);
\end{itemize}

The packages that will be used are built in to the default Anaconda
package, with exception to \texttt{pandas\_profiling}, \texttt{mlxtend},
and \texttt{pca}.

\begin{itemize}
\item
  \texttt{pandas\_profiling} (from
  https://github.com/pandas-profiling/pandas-profiling) was leveraged to
  provide a detailed exploratory analysis of our data, and the
  attributes we would be working with. Data profiling is crucial to the
  measurement of the quality of data, which in turn greatly assists the
  analyst team in their discovery of data anomalies/inconsistencies, and
  as such, appropriate data transformations and/or pre-processing
  actions. The data-profiling reports (generated by this package) will
  be referenced in our project discussion, with the full resource
  located in the appendix.
\item
  \texttt{mlxtend} (from https://github.com/rasbt/mlxtend) was used in
  our Association Rule Mining section, to assist in the mining of such
  associated rules.
\item
  \texttt{pca} (from https://github.com/erdogant/pca) was used for
  graphical presentation of the Principal Component Analysis.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{raw\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./data/raw/mobile\PYZus{}price.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{raw\PYZus{}metadata} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}excel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./data/raw/ColumnDescription.xlsx}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{index\PYZus{}col}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Column}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{raw\PYZus{}data}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{raw\PYZus{}metadata}\PY{o}{.}\PY{n}{to\PYZus{}dict}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Explaination}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{profiling-report}{%
\subsection{Profiling Report}\label{profiling-report}}

With the imported metadata, and raw dataset, we can now populate and
generate a \texttt{pandas\_profiling} report. For reference, see
\texttt{Raw\ Data\ Profiling\ Report}, in the apendix.

    \hypertarget{raw-data---interpretation-analysis-and-cleaning}{%
\subsection{Raw Data - Interpretation, Analysis, and
Cleaning}\label{raw-data---interpretation-analysis-and-cleaning}}

Here, we will walk through the fields presented in the raw data, stating
assumptions/decisions, and undertaking any appropriate cleaning steps.
In the event of changes, we will apply them to the
\texttt{staging\_data} data frame, and \texttt{staging\_metadata}
dictionary.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Clone the raw data \PYZam{} metadata }
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{raw\PYZus{}data}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{staging\PYZus{}metadata} \PY{o}{=} \PY{n}{raw\PYZus{}metadata}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} By default the new\PYZus{}name is the old\PYZus{}name}
\PY{n}{staging\PYZus{}metadata}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{index}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} helper functions}
    
\PY{k}{def} \PY{n+nf}{string\PYZus{}to\PYZus{}bool}\PY{p}{(}\PY{n}{value}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Converts String representation of Boolean (\PYZdq{}yes\PYZdq{}, \PYZdq{}has\PYZdq{})/(\PYZdq{}no\PYZdq{},\PYZdq{}not\PYZdq{}) to True/False}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{k}{if} \PY{n}{value}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yes}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{:}
        \PY{k}{return} \PY{k+kc}{True}
    \PY{k}{elif} \PY{n}{value}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{no}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{not}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{:}
        \PY{k}{return} \PY{k+kc}{False}
    \PY{k}{return} \PY{k+kc}{None}


\PY{k}{def} \PY{n+nf}{int\PYZus{}to\PYZus{}bool}\PY{p}{(}\PY{n}{value}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Converts int representation of Boolean (1, 0) to True/False}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{k}{return} \PY{n}{value} \PY{o}{==} \PY{l+m+mi}{1}


\PY{k}{def} \PY{n+nf}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PY{n}{target\PYZus{}col}\PY{p}{,} \PY{n}{new\PYZus{}col\PYZus{}name}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    This function discretises the column}
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{c+c1}{\PYZsh{} Default value of new col}
    \PY{k}{if} \PY{n}{new\PYZus{}col\PYZus{}name} \PY{o+ow}{is} \PY{k+kc}{None}\PY{p}{:}
        \PY{n}{new\PYZus{}col\PYZus{}name} \PY{o}{=} \PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{target\PYZus{}col}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}
        
    \PY{n}{col\PYZus{}holder} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{n}{target\PYZus{}col}\PY{p}{]}
    \PY{n}{df}\PY{p}{[}\PY{n}{new\PYZus{}col\PYZus{}name}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{0} \PY{c+c1}{\PYZsh{} Initialise}
    
    \PY{k}{if} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category}\PY{p}{:}
        \PY{n}{df}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{col\PYZus{}holder}\PY{o}{\PYZgt{}}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{new\PYZus{}col\PYZus{}name}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{col\PYZus{}holder}\PY{p}{[}\PY{n}{col\PYZus{}holder}\PY{o}{\PYZgt{}}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,}\PY{n}{include\PYZus{}lowest}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{k}{else}\PY{p}{:}
        \PY{n}{df}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{n}{new\PYZus{}col\PYZus{}name}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{col\PYZus{}holder}\PY{p}{,}\PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,}\PY{n}{include\PYZus{}lowest}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    
    \PY{k}{return} \PY{n}{df}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{id}{%
\paragraph{\texorpdfstring{\texttt{ID}}{ID}}\label{id}}

The id field is unique, and it seems to be a good candidate for primary
key. Note, we will NOT be using ID for any analysis, as it is an
irrelevant attribute.

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{battery_power}{%
\paragraph{\texorpdfstring{\texttt{battery\_power}}{battery\_power}}\label{battery_power}}

The battery\_power has 1094 distinct counts, approximately half the
distinct counts of id. This data is continuous, and as such, we shall
discretise for the later association rule mining.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{battery\PYZus{}power}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{blue}{%
\paragraph{\texorpdfstring{\texttt{blue}}{blue}}\label{blue}}

This (``has bluetooth'') field is a categorical data type
(\emph{boolean}), expressed (poorly) in string-form, with many
inconsistencies. We observe 10 distinct values that all refer to either
the phone having bluetooth (True), or not having bluetooth (False). The
inconsistencies must be attributed to an appropriate boolean value, and
as such, this field needs to be cleaned.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}bluetooth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{string\PYZus{}to\PYZus{}bool}\PY{p}{)}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}bluetooth}\PY{l+s+s2}{\PYZdq{}}  \PY{c+c1}{\PYZsh{} Rename metadata}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{clock_speed}{%
\paragraph{\texorpdfstring{\texttt{clock\_speed}}{clock\_speed}}\label{clock_speed}}

The clock\_speed attribute has 26 distinct values for which 413 of the
records have a value of 0.5. We note that the distribution of values in
the histogram is right skewed. This data is continuous and will need to
be discretised if we wish to use it in the association rule mining
process.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{clock\PYZus{}speed}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{dual_sim}{%
\paragraph{\texorpdfstring{\texttt{dual\_sim}}{dual\_sim}}\label{dual_sim}}

The dual\_sim attirbute is similar to the \texttt{blue} /
\texttt{has\_bluetooth} attribute, wherein it is a categorical datatype
(\emph{boolean}) with its inconsistencies forming 10 (\emph{string})
distinct values. Hence, the procedure of cleaning will be similar.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}dual\PYZus{}sim}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dual\PYZus{}sim}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{string\PYZus{}to\PYZus{}bool}\PY{p}{)}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dual\PYZus{}sim}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}dual\PYZus{}sim}\PY{l+s+s2}{\PYZdq{}}  \PY{c+c1}{\PYZsh{} Rename metadata}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{fc}{%
\paragraph{\texorpdfstring{\texttt{fc}}{fc}}\label{fc}}

The (\emph{Front Camera}) \texttt{fc} attribute has 474 (23.7\% of the
dataset) zero values. We will be interpreting the zero values as ``this
phone does not have a front camera'' (please see the \textbf{\emph{Data
Privacy Disclaimer}} below). This continous data will be discretised for
later (association rule mining) purposes, with present zero values (as a
result of our domain interpretation) populating their own level within
this category.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{front\PYZus{}cam\PYZus{}resolution}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{front\PYZus{}cam\PYZus{}resolution}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Rename metadata}
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{front\PYZus{}cam\PYZus{}resolution}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{four_g}{%
\paragraph{\texorpdfstring{\texttt{four\_g}}{four\_g}}\label{four_g}}

The \texttt{four\_g} attribute is a categorical (\emph{boolean})
attribute, with values indicated as \texttt{yes\ =\ 1} and
\texttt{no\ =\ 0} regarding (the phone's) 4G capability. For
consistency, this will be converted from current numeric form to boolean
type.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}four\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{four\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{int\PYZus{}to\PYZus{}bool}\PY{p}{)}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{four\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}four\PYZus{}g}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Rename metadata}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

    \hypertarget{int_memory}{%
\paragraph{\texorpdfstring{\texttt{int\_memory}}{int\_memory}}\label{int_memory}}

The \texttt{int\_memory} (\emph{Internal Memory}) attribute has 63
distinct values that vary as shown in the \emph{profiling-report}
histogram. There are no records of phones having \texttt{0\ GB} as the
storage which would be expected, as phones would require a minimum
amount of memory to host their respective operating software/s. This
continuous data will be discretised for later use in the association
rule mining phase.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{int\PYZus{}memory}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{m_dep}{%
\paragraph{\texorpdfstring{\texttt{m\_dep}}{m\_dep}}\label{m_dep}}

The \texttt{m\_dep} (\emph{Mobile Depth}) attribute has 10 distinct
values that vary as shown in the \emph{profiling-report} histogram. The
minimum values do not make much sense, however, please refer to the
\textbf{\emph{Data Privacy Disclaimer}} below. Additionally, this
continuous data will be discretised for later (association rule mining)
purposes.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{m\PYZus{}dep}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{m\PYZus{}dep}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}  \PY{c+c1}{\PYZsh{} Rename metadata}
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{mobile_wt}{%
\paragraph{\texorpdfstring{\texttt{mobile\_wt}}{mobile\_wt}}\label{mobile_wt}}

The \texttt{mobile\_wt} (\emph{Mobile Weight}) attribute has 121
distinct values that vary as shown in the \emph{profiling-report}
histogram. The respective min and max values are \texttt{80} and
\texttt{200}, measured in presumably grams. This continuous data will be
discritised for later association rule mining purposes.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}weight}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}wt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} 
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}wt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}weight}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Rename metadata}
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}weight}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{n_cores}{%
\paragraph{\texorpdfstring{\texttt{n\_cores}}{n\_cores}}\label{n_cores}}

The \texttt{n\_cores} (\emph{Number of Cores}) attribute looks almost
uniform in the range \texttt{1-8}. This is categorical (numerical) data,
and requires no further attention at this moment.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{number\PYZus{}of\PYZus{}cores}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{n\PYZus{}cores}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{n\PYZus{}cores}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{number\PYZus{}of\PYZus{}cores}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Rename metadata}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{pc}{%
\paragraph{\texorpdfstring{\texttt{pc}}{pc}}\label{pc}}

The \texttt{pc} (\emph{Primary Camera Resolution}) attribute displays 21
distinct values, with 101 zero values (5.1\% of the data). We will be
interpreting the zero values as ``this phone does not have a primary
camera'', (please see the \textbf{\emph{Data Privacy Disclaimer}}
below). This continuous data will be discretised for later (association
rule mining) purposes, with present zero values (as a result of our
domain interpretation) populating their own level within this category.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{primary\PYZus{}cam\PYZus{}resolution}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{primary\PYZus{}cam\PYZus{}resolution}\PY{l+s+s2}{\PYZdq{}}
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{primary\PYZus{}cam\PYZus{}resolution}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{px_height}{%
\paragraph{\texorpdfstring{\texttt{px\_height}}{px\_height}}\label{px_height}}

The \texttt{px\_height} (\emph{Pixel Height}) attribute has a
right-skewed, normal distribution, with a mean and standard deviation of
\texttt{645} and \texttt{443.79} pixels (respectively), and values
falling in the range \texttt{0-1960}. We will be interpreting the two
zero values as \emph{extremely small, but not zero} values, (please see
the \textbf{\emph{Data Privacy Disclaimer}} below). This notion also
applies to the nonsensical low values. For association rule mining
purposes, this continuous data will be discretised, wherein (as per the
assumption above) the zero values will fall within the first category,
shared by other values (relatively) close to zero.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{px\PYZus{}height}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{px_width}{%
\paragraph{\texorpdfstring{\texttt{px\_width}}{px\_width}}\label{px_width}}

The \texttt{px\_width} (\emph{Pixel Width}) attribute has a varying
distribution of values in the range 500 to 1998. This continuous data
will be discretised, for later (association rule mining) purposes.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{px\PYZus{}width}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{ram}{%
\paragraph{\texorpdfstring{\texttt{ram}}{ram}}\label{ram}}

The \texttt{ram} attribute has a varying distribution of values in the
range \texttt{256-3998}. This continuous data will be discretised, for
later (association rule mining) purposes.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Discretizing ram}
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ram}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{sc_h}{%
\paragraph{\texorpdfstring{\texttt{sc\_h}}{sc\_h}}\label{sc_h}}

The \texttt{sc\_h} (\emph{Screen Height}) attributes has 15 distinct
values with a range of \texttt{5-19}. This continuous data will be
discretised, for later (association rule mining) purposes.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}height}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sc\PYZus{}h}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sc\PYZus{}h}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}height}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Rename metadata}
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}height}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{sc_w}{%
\paragraph{\texorpdfstring{\texttt{sc\_w}}{sc\_w}}\label{sc_w}}

The \texttt{sc\_w} (\emph{Screen Width}) attribute has 19 distinct
values with a range of \texttt{0-18} with 180 zero values. These zero
values do not make \emph{real world sense}, and so we will be
interpreting any zero values as representatives of sensible, low values
(please see the \textbf{\emph{Data Privacy Disclaimer}} below). Note
that this notion also applies to any non-zero, nonsensical low values.
For association rule mining purposes, this continuous data will be
discretised, wherein (as per the assumption above) the zero values will
fall within the first category, shared by other values (relatively)
close to zero.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}width}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sc\PYZus{}w}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sc\PYZus{}w}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}width}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Rename metadata}
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}width}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{talk_time}{%
\paragraph{\texorpdfstring{\texttt{talk\_time}}{talk\_time}}\label{talk_time}}

The \texttt{talk\_time} attribute has 19 distinct values with a range
\texttt{2-20}. This continuous data will be discretised, for later
(association rule mining) purposes.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}discretised\PYZus{}col}\PY{p}{(}\PY{n}{staging\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{talk\PYZus{}time}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{is\PYZus{}zero\PYZus{}its\PYZus{}own\PYZus{}category} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{three_g}{%
\paragraph{\texorpdfstring{\texttt{three\_g}}{three\_g}}\label{three_g}}

The \texttt{three\_g} attribute is similar to the
\texttt{has\_bluetooth} and \texttt{dual\_sim} attribute, wherein it is
a categorical (\emph{boolean}) datatype, with inconsistencies spread to
10 (string) distinct values. As such, the cleaning procedure will be
similar.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}three\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{three\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{string\PYZus{}to\PYZus{}bool}\PY{p}{)}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{three\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}three\PYZus{}g}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Rename metadata}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{touch_screen}{%
\paragraph{\texorpdfstring{\texttt{touch\_screen}}{touch\_screen}}\label{touch_screen}}

The \texttt{touch\_screen} attribute is a categorical (\emph{boolean})
attribute, similar to the initial state of the imported \texttt{four\_g}
attribute. Hence, the cleaning procedure is similar.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}touch\PYZus{}screen}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{touch\PYZus{}screen}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{int\PYZus{}to\PYZus{}bool}\PY{p}{)}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{touch\PYZus{}screen}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}touch\PYZus{}screen}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Rename metadata}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{wifi}{%
\paragraph{\texorpdfstring{\texttt{wifi}}{wifi}}\label{wifi}}

The \texttt{wifi} (\emph{has wifi}) attribute is similar to
\texttt{blue},\texttt{dual\_sim} and \texttt{three\_g} attribute,
wherein it is a boolean datatype with inconsistencies spread to 10
(string) distinct values. Hence, the procedure of cleaning will be
similar.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}wifi}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{wifi}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{string\PYZus{}to\PYZus{}bool}\PY{p}{)}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{wifi}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}wifi}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Rename metadata}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{price_category}{%
\paragraph{\texorpdfstring{\texttt{price\_category}}{price\_category}}\label{price_category}}

The \texttt{price\_category} attribute is categorical (\emph{boolean})
data, similar to the representation of \texttt{four\_g} and
\texttt{touch\_screen}. Hence, the cleaning procedure is similar.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{price\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{int\PYZus{}to\PYZus{}bool}\PY{p}{)}
\PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{price\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}} \PY{c+c1}{\PYZsh{} Rename metadata}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

    \hypertarget{data-privacy-disclaimer}{%
\subsection{\texorpdfstring{\textbf{\emph{Data Privacy
Disclaimer}}}{Data Privacy Disclaimer}}\label{data-privacy-disclaimer}}

The data provided (\texttt{mobile\_prices.csv}) has had some of it's
\emph{real world} values altered for privacy and/or legal reasons. As
such, decisions were made on how to best interpret unusual / nonsensical
values equal, or approximately equal to \texttt{zero}.

\hypertarget{appropriate-zero-values}{%
\subsubsection{\texorpdfstring{\textbf{Appropriate zero
values}}{Appropriate zero values}}\label{appropriate-zero-values}}

\begin{itemize}
\tightlist
\item
  \texttt{primary\_camera\_resolution}
\item
  \texttt{front\_camera\_resolution}
\end{itemize}

Zero values for these attributes can be observed as the phone not having
the attribute. This makes sense, as not all phones have a front camera,
or primary camera.

\hypertarget{inappropriate-zero-values}{%
\subsubsection{Inappropriate zero
values}\label{inappropriate-zero-values}}

\begin{itemize}
\tightlist
\item
  \texttt{px\_height}
\item
  \texttt{screen\_width}
\end{itemize}

Zero / close to zero values for these attributes can be observed as
\textbf{values altered for privacy reasons} and should be interpreted as
a representation of a relatively low value (but \textbf{NOT} taken
literally as the stated value).

    \hypertarget{set-cleaned_data-and-discretised_data}{%
\subsection{\texorpdfstring{Set \texttt{cleaned\_data} and
\texttt{discretised\_data}}{Set cleaned\_data and discretised\_data}}\label{set-cleaned_data-and-discretised_data}}

\begin{itemize}
\tightlist
\item
  Declare our \texttt{cleaned\_data}, \texttt{discretised\_data} and
  \texttt{cleaned\_metadata};
\item
  Generate ``clean'' pandas-profiling report;
\item
  Export these to \texttt{.csv} files;
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{cleaned\PYZus{}data} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{p}{[}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{id}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{battery\PYZus{}power}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}bluetooth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{clock\PYZus{}speed}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}dual\PYZus{}sim}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{front\PYZus{}cam\PYZus{}resolution}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}four\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{int\PYZus{}memory}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}weight}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{number\PYZus{}of\PYZus{}cores}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{primary\PYZus{}cam\PYZus{}resolution}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{px\PYZus{}height}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{px\PYZus{}width}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ram}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}height}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}width}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{talk\PYZus{}time}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} 
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}three\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}touch\PYZus{}screen}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}wifi}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}

\PY{n}{discretised\PYZus{}data} \PY{o}{=} \PY{n}{staging\PYZus{}data}\PY{p}{[}\PY{p}{[}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{battery\PYZus{}power\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}bluetooth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{clock\PYZus{}speed\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}dual\PYZus{}sim}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{front\PYZus{}cam\PYZus{}resolution\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}four\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{int\PYZus{}memory\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}depth\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}weight\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{number\PYZus{}of\PYZus{}cores}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{primary\PYZus{}cam\PYZus{}resolution\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{px\PYZus{}height\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{px\PYZus{}width\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ram\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}height\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}width\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{talk\PYZus{}time\PYZus{}category}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}three\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}touch\PYZus{}screen}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}wifi}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Cleaned metadata}
\PY{n}{cleaned\PYZus{}metadata} \PY{o}{=} \PY{n}{staging\PYZus{}metadata}\PY{o}{.}\PY{n}{set\PYZus{}index}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{new\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{cleaned\PYZus{}metadata\PYZus{}dict} \PY{o}{=} \PY{n}{cleaned\PYZus{}metadata}\PY{o}{.}\PY{n}{to\PYZus{}dict}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Explaination}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{cleaned\PYZus{}metadata}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
                             Explaination
new\_name
id
ID
battery\_power                                                Total energy a
battery can store in one time measured in mAh
has\_bluetooth
Has bluetooth or not
clock\_speed                                                           speed at
which microprocessor executes instructions
has\_dual\_sim
Has dual sim support or not
front\_cam\_resolution
Front Camera mega pixels
has\_four\_g
Has 4G or not. 1 = yes , 0 = no
int\_memory
internal Memory in Gigabytes
mobile\_depth
Mobile Depth in cm
mobile\_weight
Weight of mobile phone
number\_of\_cores
Number of cores of processor
primary\_cam\_resolution
Primary Camera mega pixels
px\_height
Pixel Resolution Height
px\_width
Pixel Resolution Width
ram
Random Access Memory in Mega Bytes
screen\_height
Screen Height of mobile in cm
screen\_width
Screen Width of mobile in cm
talk\_time                                                longest time that a
single battery charge will last when you are
has\_three\_g
Has 3G or not
has\_touch\_screen
Has touch screen or not, 1 = yes, 0 = no
has\_wifi
Has wifi or not
is\_expensive            This is the target variable with indicating if the
mobile phone got a high price. 1 = yes, 0 = no
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{cleaned\PYZus{}data}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./data/cleaned/mobile\PYZus{}price.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{index}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)} \PY{c+c1}{\PYZsh{} Export cleaned\PYZus{}data}
\PY{n}{discretised\PYZus{}data}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./data/cleaned/mobile\PYZus{}price\PYZus{}discretised.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{index}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)} \PY{c+c1}{\PYZsh{} Export discretised\PYZus{}data}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{pandas-profiling-cleaned_data-and-discretised_data-reports}{%
\subsubsection{\texorpdfstring{Pandas-Profiling (\texttt{cleaned\_data}
and \texttt{discretised\_data})
Reports}{Pandas-Profiling (cleaned\_data and discretised\_data) Reports}}\label{pandas-profiling-cleaned_data-and-discretised_data-reports}}

See \texttt{Clean\ Data\ Profiling\ Report}, and
\texttt{Discretised\ Data\ Profiling\ Report} (in appendix).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Sort all the columns based on value (this will determine the Ordinal Encoder)}

\PY{n}{discretised\PYZus{}ordered\PYZus{}data} \PY{o}{=} \PY{n}{discretised\PYZus{}data}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}

\PY{k}{for} \PY{n}{column} \PY{o+ow}{in} \PY{n}{discretised\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{:}
    \PY{k}{if} \PY{n}{column} \PY{o}{!=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{is\PYZus{}expensive}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
        \PY{n}{unique\PYZus{}sorted\PYZus{}values} \PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{n}{discretised\PYZus{}data}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{str}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        \PY{n}{dictionary} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
        \PY{k}{for} \PY{n}{numeric\PYZus{}value} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{unique\PYZus{}sorted\PYZus{}values}\PY{p}{)}\PY{p}{)}\PY{p}{:}
            \PY{n}{dictionary}\PY{p}{[}\PY{n}{unique\PYZus{}sorted\PYZus{}values}\PY{p}{[}\PY{n}{numeric\PYZus{}value}\PY{p}{]}\PY{p}{]} \PY{o}{=} \PY{n}{numeric\PYZus{}value}
        \PY{n}{discretised\PYZus{}ordered\PYZus{}data}\PY{p}{[}\PY{n}{column}\PY{p}{]} \PY{o}{=} \PY{n}{discretised\PYZus{}data}\PY{p}{[}\PY{n}{column}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{value}\PY{p}{:} \PY{n}{dictionary}\PY{p}{[}\PY{n+nb}{str}\PY{p}{(}\PY{n}{value}\PY{p}{)}\PY{p}{]}\PY{p}{)}
    
\PY{n}{discretised\PYZus{}ordered\PYZus{}data}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{32}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{melted\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{melt}\PY{p}{(}\PY{n}{discretised\PYZus{}ordered\PYZus{}data}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{discretised\PYZus{}ordered\PYZus{}data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{columns}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,} \PY{n}{value\PYZus{}name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ordinal Value}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{p}{)}

\PY{n}{g} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{FacetGrid}\PY{p}{(}\PY{n}{melted\PYZus{}data}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{variable}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{hue}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{col\PYZus{}wrap}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{g}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ordinal Value}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{shade}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{g}\PY{o}{.}\PY{n}{set\PYZus{}axis\PYZus{}labels}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ordinal Values}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Relative Frequency}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{xlim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{project_with_report_files/project_with_report_68_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    This (above) shows the relative frequency graph of the discretised data,
in ordinal form, split by the phone-data's \texttt{is\_expensive} field.
The variable \texttt{ram\_category} displays a strong variance regarding
its seperation with \texttt{is\_expensive}, which following steps will
investigate further.

    \hypertarget{association-rule-mining}{%
\section{Association Rule Mining}\label{association-rule-mining}}

\hypertarget{information}{%
\subsection{Information}\label{information}}

Association rule mining (`ARM') is a technique used investigate and
uncover frequently occurring patterns, correlations, or associations,
between the characteristics of a given dataset/s or source. Association
rules comprise of two parts:

\begin{itemize}
\tightlist
\item
  antecedent (if) → An antecedent is something that is found in data;
\item
  consequent (then) → A consequent is an item that is found in
  combination with the antecedent.
\end{itemize}

    \hypertarget{arm-approach}{%
\subsection{ARM Approach}\label{arm-approach}}

Our approach is to take the characteristics of each of the phone
attributes (from our data) with the following strategy:

\begin{itemize}
\tightlist
\item
  keep the (current) cleaned data, especially the boolean values;
\item
  discretise any numeric values;
\end{itemize}

Before the ``apriori'' runs, the data should be in a form similar to:

\begin{longtable}[]{@{}llll@{}}
\toprule
has\_bluetooth & has\_dual\_sim & battery\_power\_0-100 &
\ldots{}\tabularnewline
\midrule
\endhead
True & False & True & True\tabularnewline
True & True & False & True\tabularnewline
False & True & True & False\tabularnewline
\bottomrule
\end{longtable}

\emph{For completed pre-processing, see IPython Notebook or}
\texttt{./data/cleaned/ARM\_item\_characteristics.csv}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} restructuring cleaned\PYZus{}data for association rule mining}
\PY{n}{ARM\PYZus{}data} \PY{o}{=} \PY{n}{discretised\PYZus{}data}

\PY{c+c1}{\PYZsh{} Boolean Tables}
\PY{n}{ARM\PYZus{}structured\PYZus{}data} \PY{o}{=} \PY{n}{ARM\PYZus{}data}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{p}{[}\PY{n}{item}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{ARM\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{,}\PY{n}{ARM\PYZus{}data}\PY{o}{.}\PY{n}{dtypes}\PY{p}{)} \PY{k}{if} \PY{n}{item}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{==} \PY{n}{np}\PY{o}{.}\PY{n}{bool}\PY{p}{]}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Discretise data}
\PY{n}{non\PYZus{}boolean\PYZus{}values} \PY{o}{=} \PY{n}{ARM\PYZus{}data}\PY{p}{[}\PY{p}{[}\PY{n}{item}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{k}{for} \PY{n}{item} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{ARM\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{,}\PY{n}{ARM\PYZus{}data}\PY{o}{.}\PY{n}{dtypes}\PY{p}{)} \PY{k}{if} \PY{n}{item}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{!=} \PY{n}{np}\PY{o}{.}\PY{n}{bool}\PY{p}{]}\PY{p}{]}

\PY{c+c1}{\PYZsh{} Adding extra columns from discretise data into columns}
\PY{k}{for} \PY{n}{non\PYZus{}boolean\PYZus{}column} \PY{o+ow}{in} \PY{n}{non\PYZus{}boolean\PYZus{}values}\PY{o}{.}\PY{n}{columns}\PY{p}{:}
    \PY{n}{unique\PYZus{}values\PYZus{}in\PYZus{}column} \PY{o}{=} \PY{n}{ARM\PYZus{}data}\PY{p}{[}\PY{n}{non\PYZus{}boolean\PYZus{}column}\PY{p}{]}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}
    \PY{k}{for} \PY{n}{category\PYZus{}name} \PY{o+ow}{in} \PY{n}{unique\PYZus{}values\PYZus{}in\PYZus{}column}\PY{p}{:}
        
        \PY{c+c1}{\PYZsh{} Assign true if the current category name matches the data}
        \PY{n}{ARM\PYZus{}structured\PYZus{}data}\PY{p}{[}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZob{}}\PY{n}{non\PYZus{}boolean\PYZus{}column}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZus{}}\PY{l+s+si}{\PYZob{}}\PY{n}{category\PYZus{}name}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{ARM\PYZus{}data}\PY{p}{[}\PY{n}{non\PYZus{}boolean\PYZus{}column}\PY{p}{]}\PY{o}{==}\PY{n}{category\PYZus{}name}
        
\PY{n}{ARM\PYZus{}structured\PYZus{}data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{ARM\PYZus{}structured\PYZus{}data}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./data/cleaned/ARM\PYZus{}item\PYZus{}characteristics.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)} \PY{c+c1}{\PYZsh{} export to csv}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{apriori-algorithm}{%
\subsection{Apriori Algorithm}\label{apriori-algorithm}}

Apriori (\emph{Apriori Algorithm}) is an algorithm used in
frequent-item-set / pattern mining over relational datasets. It seeks to
identify frequent, individual items in the data, and then extend them to
(incrementally) larger item sets, on the proviso that such item sets
appear sufficiently often enough in said data.

    \hypertarget{support}{%
\subsection{Support}\label{support}}

The recognition of frequently occurring patterns (in a dataset) must
first be tuned by certain analyst-defined parameters. The minimum
support acts as an `entry requirement value' that rules must
meet/exceed, for them to be considered `frequent'. A minimum support
value set too low, will not filter out patterns. If it is set too high,
this strict program's mining expedition will return no rules, or only
extremely dominant attribute-patterns. Example below, where we set
\texttt{MINIMUM\_SUPPORT\ =\ 0.1}, and then begin to mine the associated
rules.

\hypertarget{rules-by-minimum-support}{%
\subsubsection{Rules by `Minimum
Support'}\label{rules-by-minimum-support}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{36}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} This defines what is considered as a minimum item}
\PY{n}{MINIMUM\PYZus{}SUPPORT} \PY{o}{=} \PY{l+m+mf}{0.1}
\PY{n}{frequent\PYZus{}items} \PY{o}{=} \PY{n}{apriori}\PY{p}{(}\PY{n}{ARM\PYZus{}structured\PYZus{}data}\PY{p}{,}\PY{n}{min\PYZus{}support}\PY{o}{=}\PY{n}{MINIMUM\PYZus{}SUPPORT}\PY{p}{,}\PY{n}{use\PYZus{}colnames}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{display\PYZus{}markdown}\PY{p}{(}\PY{n}{frequent\PYZus{}items}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{frequent\PYZus{}items}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Processing 570 combinations | Sampling itemset size 5 4
    \end{Verbatim}

    \begin{longtable}[]{@{}rrl@{}}
\toprule
\begin{minipage}[b]{0.03\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\raggedleft
support\strut
\end{minipage} & \begin{minipage}[b]{0.82\columnwidth}\raggedright
itemsets\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
0\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.495\strut
\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
frozenset(\{`has\_bluetooth'\})\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.5095\strut
\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
frozenset(\{`has\_dual\_sim'\})\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.5215\strut
\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
frozenset(\{`has\_four\_g'\})\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
3\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.7615\strut
\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
frozenset(\{`has\_three\_g'\})\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
4\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.503\strut
\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
frozenset(\{`has\_touch\_screen'\})\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
712\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `has\_three\_g', `has\_wifi',
`screen\_width\_category\_(-0.019, 4.5{]}'\})\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
713\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `is\_expensive', `has\_three\_g',
`ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
714\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1\strut
\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
frozenset(\{`clock\_speed\_category\_(0.497, 1.125{]}', `has\_four\_g',
`has\_three\_g', `screen\_width\_category\_(-0.019, 4.5{]}'\})\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
715\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.11\strut
\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
frozenset(\{`px\_height\_category\_(-1.9609999999999999, 490.0{]}',
`front\_cam\_resolution\_category\_(0.981, 5.5{]}', `has\_four\_g',
`has\_three\_g'\})\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
716\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.105\strut
\end{minipage} & \begin{minipage}[t]{0.82\columnwidth}\raggedright
frozenset(\{`px\_height\_category\_(-1.9609999999999999, 490.0{]}',
`has\_four\_g', `has\_three\_g', `screen\_width\_category\_(-0.019,
4.5{]}'\})\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \textbf{Comment:} The (above) table demonstrates the item sets that meet
the minimum defined support (\texttt{0.1}).

    \hypertarget{confidence}{%
\subsection{Confidence}\label{confidence}}

In ARM, confidence is an indication of how often the rule has been found
to be true. The confidence value of a rule, \{ \textbf{\emph{X}}
-\textgreater{} \textbf{\emph{Y}} \} with respect to a set of
\textbf{z}'s \{\textbf{\emph{Z}}\}, is the proportion of the
\textbf{z}'s that contains \textbf{\emph{X}}, which also contains
\textbf{\emph{Y}}.

\hypertarget{rules-by-minimum-confidence}{%
\subsubsection{Rules by `Minimum
Confidence'}\label{rules-by-minimum-confidence}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{37}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{ARM\PYZus{}COLS\PYZus{}OF\PYZus{}INTEREST} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{antecedents}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{consequents}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{support}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{confidence}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lift}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{38}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{MINIMUM\PYZus{}CONFIDENCE\PYZus{}THRESHOLD} \PY{o}{=} \PY{l+m+mf}{0.20} \PY{c+c1}{\PYZsh{} this is the minimum confidence threshold to mine}
\PY{n}{rules\PYZus{}by\PYZus{}confidence} \PY{o}{=} \PY{n}{association\PYZus{}rules}\PY{p}{(}\PY{n}{frequent\PYZus{}items}\PY{p}{,} \PY{n}{metric}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{confidence}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{min\PYZus{}threshold}\PY{o}{=}\PY{n}{MINIMUM\PYZus{}CONFIDENCE\PYZus{}THRESHOLD}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Get all the rules that has mobile price}
\PY{n}{rules} \PY{o}{=} \PY{n}{rules\PYZus{}by\PYZus{}confidence}\PY{p}{[}\PY{n}{rules\PYZus{}by\PYZus{}confidence}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{consequents}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{is\PYZus{}expensive}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{issubset}\PY{p}{)}\PY{p}{]}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{confidence}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{display\PYZus{}markdown}\PY{p}{(}\PY{n}{rules}\PY{p}{[}\PY{n}{ARM\PYZus{}COLS\PYZus{}OF\PYZus{}INTEREST}\PY{p}{]}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rllrrr@{}}
\toprule
\begin{minipage}[b]{0.02\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.40\columnwidth}\raggedright
antecedents\strut
\end{minipage} & \begin{minipage}[b]{0.23\columnwidth}\raggedright
consequents\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\raggedleft
support\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\raggedleft
confidence\strut
\end{minipage} & \begin{minipage}[b]{0.05\columnwidth}\raggedleft
lift\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
0\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.856618\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
3.42647\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
frozenset(\{`is\_expensive', `has\_three\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.856618\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
4.44996\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `has\_three\_g', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.856618\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
3.42647\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
3\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
frozenset(\{`has\_touch\_screen', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.103\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.847737\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
3.39095\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
4\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
frozenset(\{`has\_three\_g', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1635\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.844961\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
3.37984\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
5\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
frozenset(\{`has\_wifi', `ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.108\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.840467\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
3.36187\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
6\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
frozenset(\{`has\_bluetooth', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.109\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.838462\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
3.35385\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
7\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
frozenset(\{`ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.209\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.832669\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
3.33068\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
8\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
frozenset(\{`has\_dual\_sim', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.115\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.824373\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
3.29749\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
9\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
frozenset(\{`ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.23\columnwidth}\raggedright
frozenset(\{`is\_expensive', `has\_three\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1635\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.651394\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
3.38387\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \textbf{Comment:} The (above) table shows a min-confidence threshold of
\texttt{0.65}, for the top \texttt{k=10} rules , and \texttt{0.43} for
the top \texttt{k=16} rules (we have omitted 6, however see
\texttt{association\_rule\_mining/rules\_by\_confidence\_minimum\_threshold\_0.20.csv}
for details.

    \hypertarget{explained-top-k-rules}{%
\subsubsection{\texorpdfstring{Explained: \texttt{top-k}
Rules}{Explained: top-k Rules}}\label{explained-top-k-rules}}

The \texttt{top-k} rules are the number (\textbf{\emph{k}}) of rules
(attribute patterns) that based on the confidence/support parameters,
occur with the highest frequency in the dataset.

For example, according to the k=1 rule (sorted by \texttt{confidence}),
if the phone has a \texttt{ram\_category} that belongs in the range
\texttt{3062.5\ -\ 3998.0}, and ALSO has 4G
(\texttt{has\_four\_g\ =\ True}), then there is a probability of 86\%
that this phone is expensive (\texttt{is\_expensive\ =\ True}).

It should also be noted that the top 16 rules (\texttt{k=16}) all have
an antecedent that contains \texttt{ram\_category} in the
\texttt{3062.5\ -\ 3998.0} range.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{39}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{display\PYZus{}markdown}\PY{p}{(}\PY{n}{rules}\PY{p}{[}\PY{n}{ARM\PYZus{}COLS\PYZus{}OF\PYZus{}INTEREST}\PY{p}{]}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{l+m+mi}{17}\PY{p}{:}\PY{l+m+mi}{21}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rllrrr@{}}
\toprule
\begin{minipage}[b]{0.02\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.35\columnwidth}\raggedright
antecedents\strut
\end{minipage} & \begin{minipage}[b]{0.26\columnwidth}\raggedright
consequents\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\raggedleft
support\strut
\end{minipage} & \begin{minipage}[b]{0.08\columnwidth}\raggedleft
confidence\strut
\end{minipage} & \begin{minipage}[b]{0.05\columnwidth}\raggedleft
lift\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
17\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
frozenset(\{`front\_cam\_resolution\_category\_(0.981, 5.5{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.26\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.116\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.26484\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
1.05936\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
18\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `has\_three\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.26\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1375\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.263663\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
1.05465\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
19\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
frozenset(\{`has\_four\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.26\columnwidth}\raggedright
frozenset(\{`is\_expensive', `has\_three\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1375\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.263663\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
1.36968\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
20\strut
\end{minipage} & \begin{minipage}[t]{0.35\columnwidth}\raggedright
frozenset(\{`has\_four\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.26\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1375\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.263663\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
1.05465\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{rules}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{association\PYZus{}rule\PYZus{}mining/rules\PYZus{}by\PYZus{}confidence\PYZus{}minimum\PYZus{}threshold\PYZus{}0.20.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \textbf{Comment:} The (above) table shows the 17th to the 20th rules,
when the minimum confidence threshold is set to \texttt{0.26}. Here, we
observe rules that do not reference \texttt{ram\_category}, showing
other attributes that can predict \texttt{is\_expensive}.

    \hypertarget{lift}{%
\subsection{Lift}\label{lift}}

Lift quantifies an association rule's ability to predict cases (as)
possessing an improved response (against the population), measured
against a random choice targeting model. An association rule is doing
well (according to lift) if the response (within the target) exceeds the
average for the population as a whole. Simply put, lift assesses the
degree to which the occurrence of one (characteristic) ``lifts'' the
occurrence of the other.

\begin{verbatim}
lift (A, B) = P( A U B ) / P(A) P(B)
\end{verbatim}

\texttt{(\ lift\ \textless{}\ 1\ \ )} → The occurrence of A is
\textbf{negatively} correlated with the occurrence of B;

\texttt{(\ lift\ \textgreater{}\ 1\ \ )} → The occurrence of A is
\textbf{positively} correlated with the occurrence of B;

\texttt{(\ lift\ =\ 1\ \ )} → The occurrence of A is
\textbf{independent} of the occurrence of B;

\hypertarget{rules-by-lift}{%
\subsubsection{Rules by `Lift'}\label{rules-by-lift}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{41}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{MINIMUM\PYZus{}LIFT\PYZus{}THRESHOLD} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mi}{5}

\PY{n}{rules\PYZus{}by\PYZus{}lift} \PY{o}{=} \PY{n}{association\PYZus{}rules}\PY{p}{(}\PY{n}{frequent\PYZus{}items}\PY{p}{,} \PY{n}{metric}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lift}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{min\PYZus{}threshold}\PY{o}{=}\PY{n}{MINIMUM\PYZus{}LIFT\PYZus{}THRESHOLD}\PY{p}{)}
\PY{n}{rules\PYZus{}by\PYZus{}lift}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{translated\PYZus{}lift}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{rules\PYZus{}by\PYZus{}lift}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lift}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}
\PY{n}{rules\PYZus{}by\PYZus{}lift}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}translated\PYZus{}lift\PYZus{}negative}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{rules\PYZus{}by\PYZus{}lift}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{translated\PYZus{}lift}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{\PYZlt{}} \PY{l+m+mi}{0}
\PY{n}{rules\PYZus{}by\PYZus{}lift}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{absolute\PYZus{}value\PYZus{}of\PYZus{}translated\PYZus{}lift}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{n}{rules\PYZus{}by\PYZus{}lift}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{translated\PYZus{}lift}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Get all the rules that has mobile price}
\PY{n}{rules} \PY{o}{=} \PY{n}{rules\PYZus{}by\PYZus{}lift}\PY{p}{[}\PY{n}{rules\PYZus{}by\PYZus{}lift}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{consequents}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{is\PYZus{}expensive}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{issubset}\PY{p}{)}\PY{p}{]}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{absolute\PYZus{}value\PYZus{}of\PYZus{}translated\PYZus{}lift}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{rules}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{association\PYZus{}rule\PYZus{}mining/rules\PYZus{}by\PYZus{}lift\PYZus{}sorted\PYZus{}by\PYZus{}absolute\PYZus{}value\PYZus{}of\PYZus{}translated\PYZus{}lift.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{43}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{display\PYZus{}markdown}\PY{p}{(}\PY{n}{rules}\PY{p}{[}\PY{n}{ARM\PYZus{}COLS\PYZus{}OF\PYZus{}INTEREST}\PY{p}{]}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rllrrr@{}}
\toprule
\begin{minipage}[b]{0.02\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.37\columnwidth}\raggedright
antecedents\strut
\end{minipage} & \begin{minipage}[b]{0.28\columnwidth}\raggedright
consequents\strut
\end{minipage} & \begin{minipage}[b]{0.05\columnwidth}\raggedleft
support\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\raggedleft
confidence\strut
\end{minipage} & \begin{minipage}[b]{0.04\columnwidth}\raggedleft
lift\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
0\strut
\end{minipage} & \begin{minipage}[t]{0.37\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.28\columnwidth}\raggedright
frozenset(\{`is\_expensive', `has\_three\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.856618\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedleft
4.44996\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.37\columnwidth}\raggedright
frozenset(\{`has\_three\_g', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.28\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.602067\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedleft
4.37867\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.37\columnwidth}\raggedright
frozenset(\{`ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.28\columnwidth}\raggedright
frozenset(\{`has\_dual\_sim', `is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
0.115\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.458167\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedleft
3.45787\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
3\strut
\end{minipage} & \begin{minipage}[t]{0.37\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.28\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.856618\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedleft
3.42647\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
4\strut
\end{minipage} & \begin{minipage}[t]{0.37\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `has\_three\_g', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.28\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.856618\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedleft
3.42647\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
5\strut
\end{minipage} & \begin{minipage}[t]{0.37\columnwidth}\raggedright
frozenset(\{`has\_touch\_screen', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.28\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
0.103\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.847737\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedleft
3.39095\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
6\strut
\end{minipage} & \begin{minipage}[t]{0.37\columnwidth}\raggedright
frozenset(\{`ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.28\columnwidth}\raggedright
frozenset(\{`is\_expensive', `has\_three\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
0.1635\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.651394\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedleft
3.38387\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
7\strut
\end{minipage} & \begin{minipage}[t]{0.37\columnwidth}\raggedright
frozenset(\{`has\_three\_g', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.28\columnwidth}\raggedright
frozenset(\{`is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
0.1635\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.844961\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedleft
3.37984\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
8\strut
\end{minipage} & \begin{minipage}[t]{0.37\columnwidth}\raggedright
frozenset(\{`ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.28\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.464143\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedleft
3.37559\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
9\strut
\end{minipage} & \begin{minipage}[t]{0.37\columnwidth}\raggedright
frozenset(\{`ram\_category\_(3062.5, 3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.28\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `is\_expensive', `has\_three\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedleft
0.464143\strut
\end{minipage} & \begin{minipage}[t]{0.04\columnwidth}\raggedleft
3.37559\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \textbf{Comment:} The (above) table shows top (\texttt{k=10}) rules,
where we notice that \texttt{ram\_category} is present in all (10)
antecedents (see
\texttt{association\_rule\_mining/rules\_by\_lift\_sorted\_by\_absolute\_value\_of\_translated\_lift.csv}
for the full list of rules).

We have ordered these rules by
\texttt{absolute\_value\_of\_translated\_lift}, in order to better
highlight the strongest attribute correlations (whether they be
positive, or negative).

\begin{itemize}
\item
  The top \texttt{k=1} rule states that when a phone has
  \texttt{ram\_category} in the range \texttt{3062.5\ -\ 3998.0}, and
  also has 4g (\texttt{has\_four\_g=true}), then these attributes are
  highly positively correlated to the \texttt{has\_three\_g} and
  \texttt{is\_expensive} attribute pair (lift=\texttt{4.449}).
\item
  It should be noted that the top (\texttt{k=17}) rules all reference
  \texttt{ram\_category} in the range \texttt{3062.5-\ 3998.0}.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{44}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{display\PYZus{}markdown}\PY{p}{(}\PY{n}{rules}\PY{p}{[}\PY{n}{ARM\PYZus{}COLS\PYZus{}OF\PYZus{}INTEREST}\PY{p}{]}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{18}\PY{p}{:}\PY{l+m+mi}{21}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rllrrr@{}}
\toprule
\begin{minipage}[b]{0.02\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedright
antecedents\strut
\end{minipage} & \begin{minipage}[b]{0.45\columnwidth}\raggedright
consequents\strut
\end{minipage} & \begin{minipage}[b]{0.06\columnwidth}\raggedleft
support\strut
\end{minipage} & \begin{minipage}[b]{0.08\columnwidth}\raggedleft
confidence\strut
\end{minipage} & \begin{minipage}[b]{0.05\columnwidth}\raggedleft
lift\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
18\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
frozenset(\{`has\_four\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.45\columnwidth}\raggedright
frozenset(\{`is\_expensive', `has\_three\_g', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.223394\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
1.36632\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
19\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
frozenset(\{`has\_three\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.45\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `is\_expensive', `ram\_category\_(3062.5,
3998.0{]}'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1165\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.152988\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
1.3132\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
20\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
frozenset(\{`has\_three\_g'\})\strut
\end{minipage} & \begin{minipage}[t]{0.45\columnwidth}\raggedright
frozenset(\{`has\_four\_g', `is\_expensive'\})\strut
\end{minipage} & \begin{minipage}[t]{0.06\columnwidth}\raggedleft
0.1375\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.180565\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedleft
1.3132\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \textbf{Comment:} The 18th up to the 20th (above) show different
attribute with a lift that is positively correlated, but not as strong
as the previous the rules.

    \hypertarget{association-rule-mining---recommendation-for-designing-an-expensive-phone}{%
\subsection{Association Rule Mining - Recommendation for Designing an
Expensive
Phone}\label{association-rule-mining---recommendation-for-designing-an-expensive-phone}}

Based on our results from association rule mining, we can advise a
manufacturer (who wishes to design an expensive phone) on the following
features\ldots{}

The most notable attribute in an item-set, that resulted in an expensive
phone, contained RAM that fell in the RAM category (range)
\texttt{3062.5-\ 3998.0}. However, within the same item-set/s as RAM, we
noted the following (most frequent) attributes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  four G
\item
  touch scren
\item
  three G
\item
  wifi
\item
  bluetooth
\end{enumerate}

\ldots ranked by the strongest defining confidence. This discovery
upholds the initial patterns that we observed in the graph of relative
frequency of all attributes (in their ordinal form), divided by the
\texttt{is\_expensive} field.

    \hypertarget{classification}{%
\section{Classification}\label{classification}}

Classification is the supervised-learning process of determining and
assigning classes to data rows. This process can identify the class of
an unknown row, based upon data row/s that a model has been trained
upon.

Classification in \texttt{CITS\ 3401\ -\ Project\ 2} will be done with
cross validation of ten folds, using differing partitions of our dataset
for testing and training, to avoid overfitting our model. Furthermore,
the training will be done with a \texttt{RANDOM\_STATE} seeding, for the
express purpose of mitigating the uncontrollable inconsistency of
algorithm that uses randomisation.

The classification will be done with both Decision Tree (`DT') and
Support Vector Machine (`SVM'), with hyperparameter optimisation. The
metric will be accuracy, as the attribute \texttt{is\_expensive} is
weighted equally (between the possible \texttt{True} or \texttt{False}
values).

We will be using the \texttt{cleaned\_data} dataset (not the wholly
discretised dataset that was used in the Association Rule Mining), as
SVM works well in seperating continuous attributes, whilst DT can take
either continuous (`Regression Tree') or discrete (`Classification
Tree') data.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{45}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Seperation of data into features and target}
\PY{n}{learning\PYZus{}data} \PY{o}{=} \PY{n}{cleaned\PYZus{}data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{id}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{columns}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{target\PYZus{}data} \PY{o}{=} \PY{n}{learning\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{feature\PYZus{}data} \PY{o}{=} \PY{n}{learning\PYZus{}data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{columns}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} classification helpers}

\PY{k}{def} \PY{n+nf}{show\PYZus{}top\PYZus{}results}\PY{p}{(} \PY{n}{gridsearch}\PY{p}{,} \PY{n}{target\PYZus{}results}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{rank\PYZus{}test\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}test\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{params}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{number\PYZus{}of\PYZus{}params}\PY{o}{=}\PY{l+m+mi}{5} \PY{p}{)}\PY{p}{:}
    
    \PY{n}{result} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{gridsearch}\PY{o}{.}\PY{n}{cv\PYZus{}results\PYZus{}}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}test\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{[}\PY{n}{target\PYZus{}results}\PY{p}{]}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{number\PYZus{}of\PYZus{}params}\PY{p}{)}
    \PY{n}{display}\PY{p}{(}\PY{n}{Markdown}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{to\PYZus{}markdown}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{decision-tree}{%
\subsection{Decision Tree}\label{decision-tree}}

A decision tree is an algorithm that separates the data using different
thresholds, within different attributes. There are two main criterium
for choosing an attribute and a threshold:

\begin{itemize}
\item
  \texttt{Gini\ Index} -\textgreater{} Information Gain calculates
  effective change in entropy after making a decision based on the value
  of an attribute.
\item
  \texttt{Information\ Gain\ (entropy)} -\textgreater{} The gini index,
  calculates the amount of probability of a specific feature that is
  classified incorrectly when selected randomly.
\end{itemize}

We will now configure and test the aforementioned classifiers\ldots{}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{47}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}1} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dt\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{n}{RANDOM\PYZus{}STATE}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Grid Search}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{entropy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{k+kc}{None}\PY{p}{]} \PY{o}{+} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}1}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{p}{,}\PY{n}{target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{49}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{show\PYZus{}top\PYZus{}results}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rrrl@{}}
\toprule
\begin{minipage}[b]{0.03\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedleft
rank\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedleft
mean\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.57\columnwidth}\raggedright
params\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
26\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.9475\strut
\end{minipage} & \begin{minipage}[t]{0.57\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 6\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
28\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.9435\strut
\end{minipage} & \begin{minipage}[t]{0.57\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 8\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
29\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
3\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.9415\strut
\end{minipage} & \begin{minipage}[t]{0.57\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 9\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
27\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
4\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.9405\strut
\end{minipage} & \begin{minipage}[t]{0.57\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 7\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
20\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
5\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedleft
0.94\strut
\end{minipage} & \begin{minipage}[t]{0.57\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': None\}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Test Scores: }\PY{l+s+si}{\PYZob{}}\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Params: }\PY{l+s+si}{\PYZob{}}\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \textbf{Comment:} The (above) table shows the top 5 hyper-parameters of
the decision tree, and the mean test scores of all CV folds. The best
mean test score (\texttt{0.9475}) has Information Gain as a criterium,
and a \texttt{decision\_tree\_max\_depth\ =\ 6}. We see \textbf{no} test
in the listed top 5 containing gini-index criterium.

    \hypertarget{decision-tree-visualization}{%
\subsubsection{Decision Tree
Visualization}\label{decision-tree-visualization}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{51}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{viz} \PY{o}{=} \PY{n}{dtreeviz}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{feature\PYZus{}data}\PY{p}{,} \PY{n}{target\PYZus{}data}\PY{p}{,}
                \PY{n}{target\PYZus{}name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{n}{feature\PYZus{}names}\PY{o}{=}\PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{,}
                \PY{n}{class\PYZus{}names}\PY{o}{=}\PY{n+nb}{list}\PY{p}{(}\PY{n}{target\PYZus{}data}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}

\PY{n}{viz}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decision\PYZus{}tree.svg}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{;}
\PY{c+c1}{\PYZsh{}viz}
\end{Verbatim}
\end{tcolorbox}

    \begin{figure}
\centering
\includegraphics{diagrams/decision_tree.png}
\caption{decision}
\end{figure}

    \textbf{Comment:} The (above) diagram shows the decision tree
visualisation. (See submission folder
\texttt{diagrams/decision\_tree.png})

    \hypertarget{support-vector-machine}{%
\subsection{Support Vector Machine}\label{support-vector-machine}}

    The `SVM' algorithm finds the best hyperplane in the multi-atribute
dimension, to seperate data into multiple, relevant classes. The
parameter/s available in SVM are:

\begin{itemize}
\tightlist
\item
  \texttt{Seperation\ Degree} of the Hyperplane (also known as
  \texttt{Kernel});
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{52}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svm\PYZus{}pipeline\PYZus{}2} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{svm\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{SVC}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Grid Search}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{svm\PYZus{}classifier\PYZus{}\PYZus{}kernel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{poly}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{svm\PYZus{}pipeline\PYZus{}2}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{p}{,}\PY{n}{target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{54}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{show\PYZus{}top\PYZus{}results}\PY{p}{(}\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rrrl@{}}
\toprule
& rank\_test\_score & mean\_test\_score & params\tabularnewline
\midrule
\endhead
0 & 1 & 0.9895 & \{'svm\_classifier\_\_kernel':
`linear'\}\tabularnewline
1 & 2 & 0.9825 & \{'svm\_classifier\_\_kernel': `poly'\}\tabularnewline
2 & 3 & 0.9785 & \{'svm\_classifier\_\_kernel': `rbf'\}\tabularnewline
3 & 4 & 0.53 & \{'svm\_classifier\_\_kernel': `sigmoid'\}\tabularnewline
\bottomrule
\end{longtable}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{55}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Mean Test Scores of different Parameters: }\PY{l+s+si}{\PYZob{}}\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Params: }\PY{l+s+si}{\PYZob{}}\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Best Mean Test Scores of different Parameters: 0.9894999999999999
Best Params: \{'svm\_classifier\_\_kernel': 'linear'\}
    \end{Verbatim}

    \textbf{Comment:} The (above) table displays the top 5 hyperparameters,
of the SVM. We observe the best mean test score of (\texttt{0.9895})
attributable to the \texttt{kernel\ =\ linear} hyperplane.

    \hypertarget{comparison-dt-vs-svm}{%
\subsection{\texorpdfstring{Comparison \texttt{DT} vs
\texttt{SVM}}{Comparison DT vs SVM}}\label{comparison-dt-vs-svm}}

Our tests conclude that SVM yields results with higher accuracies, than
DT. Though both (methods) are exposed to the same data, and their most
valuable hyperparameters are optimized, we must acknowledge that SVM is
a more appropriate algorithm for this dataset, and experiment.

    \hypertarget{clustering}{%
\section{Clustering}\label{clustering}}

Clustering is the unsupervised-learning process of assigning data to a
group, or `cluster'. Clustering identifies similarities between objects,
which it groups according to these characteristics in common, and which
differentiate them from other groups of data. The clustering process is
very similar to the classification process, aside from the classes not
being known / labelled (in clustering).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} clustering helper functions}

\PY{k}{def} \PY{n+nf}{print\PYZus{}confusion\PYZus{}table}\PY{p}{(}\PY{n}{crosstab\PYZus{}df}\PY{p}{,} \PY{n}{accuracy\PYZus{}val}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{crosstab}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ (}\PY{l+s+si}{\PYZob{}:.2f\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{)}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{accuracy}\PY{p}{,} \PY{n}{accuracy}\PY{o}{*}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{cluster-of-size-2}{%
\subsection{Cluster of Size 2}\label{cluster-of-size-2}}

The clustering method will begin with \texttt{CLUSTER\_SIZE\ =\ 2},
enabling us to compare the two distinct values of
\texttt{is\_expensive}, and the relevant clusters. This \textbf{DOES
NOT} mean that the \texttt{CLUSTER\_SIZE} set at \texttt{2}, is the
optimal cluster number.

\textbf{\emph{Example:}} \emph{There may be a phone that sits in between
\texttt{is\_expensive=True} and \texttt{is\_expensive=False} (a medium
priced phone) that a cluster size \texttt{n=2} would not be able to
properly represent.}

    \hypertarget{kmeans}{%
\subsection{Kmeans}\label{kmeans}}

\texttt{K-means} clustering aims to partition observations (data rows)
into \textbf{\emph{k}} clusters, in which each observation belongs to
the cluster with the nearest cluster-mean / cluster-centroid.

\hypertarget{confusion-table}{%
\paragraph{Confusion Table}\label{confusion-table}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{57}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{kmeans\PYZus{}model} \PY{o}{=} \PY{n}{KMeans}\PY{p}{(}\PY{n}{n\PYZus{}clusters}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{n}{RANDOM\PYZus{}STATE}\PY{p}{)}
\PY{n}{kmeans\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{p}{)}
\PY{n}{kmeans\PYZus{}prediction} \PY{o}{=} \PY{n}{kmeans\PYZus{}model}\PY{o}{.}\PY{n}{labels\PYZus{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{confusion\PYZus{}matrix} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{)}
\PY{c+c1}{\PYZsh{} target\PYZus{}data}
\PY{n}{confusion\PYZus{}matrix}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{target}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{target\PYZus{}data}
\PY{n}{confusion\PYZus{}matrix}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{prediction}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{kmeans\PYZus{}prediction}
\PY{n}{crosstab} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{crosstab}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{confusion\PYZus{}matrix}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{prediction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{accuracy} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{diagonal}\PY{p}{(}\PY{n}{crosstab}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n}{crosstab}\PY{o}{.}\PY{n}{to\PYZus{}numpy}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{59}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{print\PYZus{}confusion\PYZus{}table}\PY{p}{(}\PY{n}{crosstab}\PY{p}{,} \PY{n}{accuracy}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
prediction    0    1
target
False       977  523
True          0  500
--------------------------
Accuracy: 0.7385 (73.85\%)
--------------------------
    \end{Verbatim}

    \textbf{Comment:} The confusion table (above) shows a \texttt{73.85\%}
accuracy when matched with the labelled groups, wherein the other
26.15\% inaccuracy can be explained by kmeans predicting a phone
\texttt{is\_expensive} when it is in fact not (false positive), and 0\%
for false negative.

    \hypertarget{validation-of-two-cluster-size}{%
\subsection{Validation of Two Cluster
Size}\label{validation-of-two-cluster-size}}

In the previous heading, it is assumed that the cluster of size 2 is
expected. This is an extra exploratory step to validate whether a
cluster of size 2 is the best way to split the data.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{60}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{cluster\PYZus{}evaluation} \PY{o}{=} \PY{n}{clusteval}\PY{p}{(}\PY{n}{method}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{silhouette}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{cluster}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{kmeans}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} 
\PY{n}{cluster\PYZus{}evaluation}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{p}{)}\PY{p}{)}
\PY{n}{cluster\PYZus{}evaluation}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
  4\%|███▋
| 1/23 [00:00<00:03,  6.85it/s]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

[clusteval] >Fit using kmeans with metric: euclidean, and linkage: ward
[clusteval] >Evaluate using silhouette.
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
100\%|███████████████████████████████████████████████████████████████████████████
██████████| 23/23 [00:06<00:00,  3.82it/s]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[clusteval] >Optimal number clusters detected: [2].
[clusteval] >Fin.
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{project_with_report_files/project_with_report_124_4.png}
    \end{center}
    { \hspace*{\fill} \\}
    
            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{60}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
(<Figure size 1080x576 with 1 Axes>,
 <AxesSubplot:title=\{'center':'silhouette score versus number of clusters'\},
xlabel='\#Clusters', ylabel='Score'>)
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{silhouette-score}{%
\subsubsection{Silhouette Score}\label{silhouette-score}}

Silhouette score refers to a method of interpretation and validation of
consistency within clusters of data. The higher the score, the better
the overall cluster measure, such as within-variability and
between-variability of the clusters. According to the chart (above) a
\texttt{CLUSTER\_SIZE\ =\ 2} is most appropriate.

    \hypertarget{data-reduction}{%
\section{Data Reduction}\label{data-reduction}}

More data is not always the solution. When working with `big data' we
must consider the issues around redundancy, outliers, and storage. Data
reduction (as the name suggests) actively encourages the reduction of
data, where possible, through the elimination of data-rows (numerosity),
and data-columns (features). This reduction must be weighed in against
the overall quality/information that would be forfeited.

\hypertarget{reasons-for-reducing-data}{%
\subsection{Reasons for Reducing Data}\label{reasons-for-reducing-data}}

\begin{itemize}
\tightlist
\item
  Increases storage capacity
\item
  Easy and efficient Mining, reduces time and memory requirement
\item
  Easy visualisation
\item
  Help to eliminate irrelevant /redundant features
\item
  Reduces noise
\end{itemize}

    \hypertarget{numerosity-reduction}{%
\subsection{Numerosity Reduction}\label{numerosity-reduction}}

Numerosity reduction involves the replacement of voluminous data, with
an alternate, smaller form of data representation. This exchange can be
achieved via parametric and non-parametric methods.

\begin{itemize}
\item
  \texttt{Parametric\ Numerosity\ Reduction} -\textgreater{} These
  techniques include linear regression and log linear models, to which
  the model's parameters can be stored, instead of the FULL data
  representation.
\item
  \texttt{Non-Parametric\ Numerosity\ Reduction} -\textgreater{}
  Sampling, histograms, clustering, data cube aggregation.
\end{itemize}

    \hypertarget{numerosity-reduction---sampling-with-decision-tree}{%
\subsubsection{Numerosity Reduction - Sampling with Decision
Tree}\label{numerosity-reduction---sampling-with-decision-tree}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}1} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dt\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{n}{RANDOM\PYZus{}STATE}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Grid Search}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{entropy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{k+kc}{None}\PY{p}{]} \PY{o}{+} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{62}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sampled\PYZus{}learning\PYZus{}data} \PY{o}{=} \PY{n}{learning\PYZus{}data}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n}{frac}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{n}{RANDOM\PYZus{}STATE}\PY{p}{)}
\PY{n}{sampled\PYZus{}target\PYZus{}data} \PY{o}{=} \PY{n}{sampled\PYZus{}learning\PYZus{}data}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
\PY{n}{sampled\PYZus{}feature\PYZus{}data} \PY{o}{=} \PY{n}{sampled\PYZus{}learning\PYZus{}data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{columns}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}1}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{sampled\PYZus{}feature\PYZus{}data}\PY{p}{,}\PY{n}{sampled\PYZus{}target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{64}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Results in Tabular format}
\PY{n}{show\PYZus{}top\PYZus{}results}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rrrl@{}}
\toprule
\begin{minipage}[b]{0.03\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\raggedleft
rank\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\raggedleft
mean\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.56\columnwidth}\raggedright
params\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
0\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
0.928\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `gini', 'dt\_classifier\_\_max\_depth':
None\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
10\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
0.928\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `gini', 'dt\_classifier\_\_max\_depth':
10\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
19\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
0.928\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `gini', 'dt\_classifier\_\_max\_depth':
19\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
18\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
0.928\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `gini', 'dt\_classifier\_\_max\_depth':
18\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
17\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
0.928\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `gini', 'dt\_classifier\_\_max\_depth':
17\}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \textbf{Comment:} Though we see (above) a drop in
\texttt{mean\_test\_score} by \texttt{1.2\%} (which is not surprising),
the amount of data needed for testing and training has been cut by
\texttt{50\%}.

    \hypertarget{numerosity-reduction---sampling-with-support-vector-machine}{%
\subsubsection{Numerosity Reduction - Sampling with Support Vector
Machine}\label{numerosity-reduction---sampling-with-support-vector-machine}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{65}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svm\PYZus{}pipeline\PYZus{}2} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{svm\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{SVC}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Grid Search}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{svm\PYZus{}classifier\PYZus{}\PYZus{}kernel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{poly}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{svm\PYZus{}pipeline\PYZus{}2}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{sampled\PYZus{}feature\PYZus{}data}\PY{p}{,}\PY{n}{sampled\PYZus{}target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{67}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Results in Tabular format}
\PY{n}{show\PYZus{}top\PYZus{}results}\PY{p}{(}\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rrrl@{}}
\toprule
& rank\_test\_score & mean\_test\_score & params\tabularnewline
\midrule
\endhead
0 & 1 & 0.982 & \{'svm\_classifier\_\_kernel': `linear'\}\tabularnewline
1 & 2 & 0.977 & \{'svm\_classifier\_\_kernel': `poly'\}\tabularnewline
2 & 3 & 0.974 & \{'svm\_classifier\_\_kernel': `rbf'\}\tabularnewline
3 & 4 & 0.548 & \{'svm\_classifier\_\_kernel':
`sigmoid'\}\tabularnewline
\bottomrule
\end{longtable}

    
    \textbf{Comment:} (Above) Similar to the results from the numerosity
reduction with the Decision Tree, we have observed an insignificant drop
in accuracy from the default SVM model (accuracy of \texttt{98.95\%}) to
the numerosity reduced SVM model (accuracy \texttt{98.2\%}).

    \hypertarget{attribute-reduction-attribute-selection}{%
\subsection{Attribute Reduction \& Attribute
Selection}\label{attribute-reduction-attribute-selection}}

Attribute reduction focuses on (no surprise) the reduction of the data's
columns/attributes. Data in a high-dimensional space will be transformed
(by attribute reduction methods) into a low-dimensional space, so that
this new, low-dimensional representation may retain appropriate amounts
of meaningful properties (from the original data), whilst \textbf{also}
heavily reducing the computational-power-requirements (storage,
navigation, transformation etc).

It achieves this mainly through discovering the attributes that possess
the lowest `predictive value', i.e.~they contribute little to the domain
specific question or are insignificant in aiding attributes that
\emph{are} contributing.

    \hypertarget{principal-component-analysis-pca}{%
\subsubsection{Principal Component Analysis
(PCA)}\label{principal-component-analysis-pca}}

\textbf{Variance} -\textgreater{} In the field of statistics, variance
is one of the most important measures, as it examines how the data
varies within (internally) and inbetween (interactively) attributes.

PCA summarises the attributes of the model through linear combinations
expressed as `principal components' (`PC') that maximises the variance.
The variance contribution of the principal components (to the data) are
ordered such that the first principal component is the `most valuable'
or `highest contributory' attribute. Furthermore, one of the
requirements of PCA is that the data is scaled, as the linear
combination is sensitive to (attribute value) ranges (values with large
magnitude value ranges will dominate the other PCs).

It should be noted that although PCA does a good job of multidimensional
to low-dimensional data summarisation, it makes it \textbf{\emph{very}}
difficult to determine which domain specific attribute/s is the one/s
contributing to the model.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{68}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{model} \PY{o}{=} \PY{n}{pca}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mf}{0.95}\PY{p}{)} \PY{c+c1}{\PYZsh{} explains 95\PYZpc{} of variance}
\PY{n}{scaled\PYZus{}data} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{p}{)}
\PY{n}{results} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{scaled\PYZus{}data}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[pca] >Column labels are auto-completed.
[pca] >Row labels are auto-completed.
[pca] >The PCA reduction is performed to capture [95.0\%] explained variance
using the [20] columns of the input data.
[pca] >Fitting using PCA..
[pca] >Computing loadings and PCs..
[pca] >Computing explained variance..
[pca] >Number of components is [18] that covers the [95.00\%] explained variance.
[pca] >Outlier detection using Hotelling T2 test with alpha=[0.05] and
n\_components=[5]
[pca] >Outlier detection using SPE/DmodX with n\_std=[2]
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{project_with_report_files/project_with_report_141_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{68}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
(<Figure size 720x576 with 1 Axes>,
 <AxesSubplot:title=\{'center':'Cumulative explained variance\textbackslash{}n 18 Principal
Components explain [95.0\%] of the variance.'\}, xlabel='Principle Component',
ylabel='Percentage explained variance'>)
\end{Verbatim}
\end{tcolorbox}
        
    
    \begin{Verbatim}[commandchars=\\\{\}]
<Figure size 432x288 with 0 Axes>
    \end{Verbatim}

    
    \textbf{Comment:} According to the total contributions, to be able to
explain 95\% of the data's variance, there is a requirement to retain 18
principal components. It should be noted that this is most unusual for
PCA, with most PCA's having 95\% of the (data's) variance explained by
only a tiny subset of the data's total dimensions.

    \hypertarget{attribute-reduction---decision-tree-with-pca}{%
\subsubsection{Attribute Reduction - Decision Tree with
PCA}\label{attribute-reduction---decision-tree-with-pca}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}3} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{scale}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pca}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{PCA}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dt\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{n}{RANDOM\PYZus{}STATE}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Grid Search}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pca\PYZus{}\PYZus{}n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{entropy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{k+kc}{None}\PY{p}{]} \PY{o}{+} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}3\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}3}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{dt\PYZus{}pipeline\PYZus{}3\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{p}{,}\PY{n}{target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{71}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{show\PYZus{}top\PYZus{}results}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}3\PYZus{}search}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rrrl@{}}
\toprule
\begin{minipage}[b]{0.03\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\raggedleft
rank\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\raggedleft
mean\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.62\columnwidth}\raggedright
params\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
568\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
0.8395\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 9, 'pca\_\_n\_components': 18\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
682\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
0.8385\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 15, 'pca\_\_n\_components': 18\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
566\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
3\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
0.8385\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 9, 'pca\_\_n\_components': 16\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
567\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
3\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
0.8385\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 9, 'pca\_\_n\_components': 17\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
663\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
5\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedleft
0.838\strut
\end{minipage} & \begin{minipage}[t]{0.62\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 14, 'pca\_\_n\_components': 18\}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Test Scores: }\PY{l+s+si}{\PYZob{}}\PY{n}{dt\PYZus{}pipeline\PYZus{}3\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Params: }\PY{l+s+si}{\PYZob{}}\PY{n}{dt\PYZus{}pipeline\PYZus{}3\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \textbf{Comment:} The results from our Decision Tree attribute reduction
with PCA demonstrated a \textbf{significant} decrease in accuracy (from
un-reduced accuracy of \texttt{94.75\%}, to \texttt{83.95\%}. These
results come as no surprise, as per results earlier, there is an unusual
contribution to total variance of PCA. We should also consider the
possibility that the summarisation of attributes to principal components
increased the impact that outliers exerted upon the (outlier sensitive)
decision tree model.

    \hypertarget{attribute-reduction---support-vector-machine-with-pca}{%
\subsubsection{Attribute Reduction - Support Vector Machine with
PCA}\label{attribute-reduction---support-vector-machine-with-pca}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svm\PYZus{}pipeline\PYZus{}3} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{scale}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pca}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{PCA}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{svm\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{SVC}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Grid Search}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pca\PYZus{}\PYZus{}n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{svm\PYZus{}classifier\PYZus{}\PYZus{}kernel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{poly}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{precomputed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svm\PYZus{}pipeline\PYZus{}3\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{svm\PYZus{}pipeline\PYZus{}3}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{svm\PYZus{}pipeline\PYZus{}3\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{p}{,}\PY{n}{target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{75}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{show\PYZus{}top\PYZus{}results}\PY{p}{(}\PY{n}{svm\PYZus{}pipeline\PYZus{}3\PYZus{}search}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rrrl@{}}
\toprule
& rank\_test\_score & mean\_test\_score & params\tabularnewline
\midrule
\endhead
85 & 1 & 0.991 & \{'pca\_\_n\_components': 18,
'svm\_classifier\_\_kernel': `linear'\}\tabularnewline
80 & 1 & 0.991 & \{'pca\_\_n\_components': 17,
'svm\_classifier\_\_kernel': `linear'\}\tabularnewline
90 & 3 & 0.9895 & \{'pca\_\_n\_components': 19,
'svm\_classifier\_\_kernel': `linear'\}\tabularnewline
75 & 4 & 0.984 & \{'pca\_\_n\_components': 16,
'svm\_classifier\_\_kernel': `linear'\}\tabularnewline
88 & 5 & 0.9785 & \{'pca\_\_n\_components': 18,
'svm\_classifier\_\_kernel': `sigmoid'\}\tabularnewline
\bottomrule
\end{longtable}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Test Scores: }\PY{l+s+si}{\PYZob{}}\PY{n}{svm\PYZus{}pipeline\PYZus{}3\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Params: }\PY{l+s+si}{\PYZob{}}\PY{n}{svm\PYZus{}pipeline\PYZus{}3\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best CV Index: }\PY{l+s+si}{\PYZob{}}\PY{n}{svm\PYZus{}pipeline\PYZus{}3\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}index\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \textbf{Comment:} The results (above) show the minimal improvement in
accuracy, when the SVM model undertook the attribute reduction process.
SVM is more robust to noise and outliers (than Decision Trees), and so
it may be possible that contrary to above, it increased the impact of
the ``good quality'' data, rather than the outlier data.

Prior to reduction, we observed an accuracy of \texttt{98.95\%}, which
then increased to \texttt{99.1\%}.

    \hypertarget{select-k-best-with-information-gain-entropy-and-anova-f-statistic}{%
\subsection{Select K-Best with Information Gain (Entropy) and ANOVA
F-statistic}\label{select-k-best-with-information-gain-entropy-and-anova-f-statistic}}

There are multiple ways to select the best attribute/s of a dataset,
mainly through the removal of redundant (highly-corellated) or
irrelevant features. The common methods include `F-statistic', and
`Information Gain'. F-statistic iteratively picks the attribute that
\emph{maximises} the varaiance (rather than a combination of attributes,
seen in PCA).

\textbf{Information gain} measures the entropy-information available in
a probability distribution. E.g :

\begin{itemize}
\tightlist
\item
  Skewed Probability Distribution (unsurprising) -\textgreater{} Low
  entropy.
\item
  Balanced Probability Distribution (surprising) -\textgreater{} High
  entropy.
\end{itemize}

    \hypertarget{attribute-reduction---decision-tree-with-select-k-best}{%
\subsubsection{Attribute Reduction - Decision Tree with Select
K-Best}\label{attribute-reduction---decision-tree-with-select-k-best}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{77}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}4} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{select\PYZus{}kbest}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SelectKBest}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dt\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{n}{RANDOM\PYZus{}STATE}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Grid Search}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{select\PYZus{}kbest\PYZus{}\PYZus{}k}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{select\PYZus{}kbest\PYZus{}\PYZus{}score\PYZus{}func}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{n}{f\PYZus{}classif}\PY{p}{,}\PY{n}{mutual\PYZus{}info\PYZus{}classif}\PY{p}{]}\PY{p}{,} \PY{c+c1}{\PYZsh{} F\PYZhy{}value statistic and Information Gain (entropy)}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{entropy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{c+c1}{\PYZsh{} \PYZhy{} Entropy is better than GINI from previous results}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{k+kc}{None}\PY{p}{]} \PY{o}{+} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}4\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}4}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{dt\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{p}{,}\PY{n}{target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{79}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{show\PYZus{}top\PYZus{}results}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rrrl@{}}
\toprule
\begin{minipage}[b]{0.02\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.08\columnwidth}\raggedleft
rank\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.08\columnwidth}\raggedleft
mean\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.70\columnwidth}\raggedright
params\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
332\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.9515\strut
\end{minipage} & \begin{minipage}[t]{0.70\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 8, 'select\_kbest\_\_k': 15,
'select\_kbest\_\_score\_func': \textless function f\_classif at
0x0000027B4261E5E0\textgreater\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
260\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.9515\strut
\end{minipage} & \begin{minipage}[t]{0.70\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 6, 'select\_kbest\_\_k': 17,
'select\_kbest\_\_score\_func': \textless function f\_classif at
0x0000027B4261E5E0\textgreater\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
256\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.9515\strut
\end{minipage} & \begin{minipage}[t]{0.70\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 6, 'select\_kbest\_\_k': 15,
'select\_kbest\_\_score\_func': \textless function f\_classif at
0x0000027B4261E5E0\textgreater\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
250\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.9515\strut
\end{minipage} & \begin{minipage}[t]{0.70\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 6, 'select\_kbest\_\_k': 12,
'select\_kbest\_\_score\_func': \textless function f\_classif at
0x0000027B4261E5E0\textgreater\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
336\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
5\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedleft
0.951\strut
\end{minipage} & \begin{minipage}[t]{0.70\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 8, 'select\_kbest\_\_k': 17,
'select\_kbest\_\_score\_func': \textless function f\_classif at
0x0000027B4261E5E0\textgreater\}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Test Scores: }\PY{l+s+si}{\PYZob{}}\PY{n}{dt\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Params: }\PY{l+s+si}{\PYZob{}}\PY{n}{dt\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best CV Index: }\PY{l+s+si}{\PYZob{}}\PY{n}{dt\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}index\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{attribute-selection-with-f-statistic-prior-to-decision-tree}{%
\subsubsection{Attribute Selection with F-Statistic prior to Decision
Tree}\label{attribute-selection-with-f-statistic-prior-to-decision-tree}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{81}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{select\PYZus{}k\PYZus{}best} \PY{o}{=} \PY{n}{dt\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{attributes\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{attribute\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{get\PYZus{}support}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{scores\PYZus{}}\PY{p}{[}\PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{get\PYZus{}support}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{attributes\PYZus{}df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{attribute\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{kind}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{barh}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{logx}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Attributes: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{attributes\PYZus{}df}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Number of Attributes: 15
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{project_with_report_files/project_with_report_162_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Comments:} The table and graph (above) display the small
improvement in the accuracy percentge, when the Decision Tree model
experienced the `select k-best' attribute reduction (an increase from
\texttt{94.75\%} to \texttt{95.15\%}).

We see the reduction method has left us with 15 attributes, in
comparison to the 18 attributes in PCA.

In this scenario, it appears that F-statistic is `better' than
information gain, with regard to the transformation. Note however, that
information gain is later used for the decision tree classifier.

    \hypertarget{attribute-selection---with-information-gain-prior-to-decision-tree}{%
\subsubsection{Attribute Selection - With Information Gain, Prior to
Decision
Tree}\label{attribute-selection---with-information-gain-prior-to-decision-tree}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}4} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{select\PYZus{}kbest}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SelectKBest}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dt\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{n}{RANDOM\PYZus{}STATE}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Grid Search \PYZhy{} REDUCED BECAUSE IT IS TAKING A LONG TIME}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{select\PYZus{}kbest\PYZus{}\PYZus{}k}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{18}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{select\PYZus{}kbest\PYZus{}\PYZus{}score\PYZus{}func}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{n}{mutual\PYZus{}info\PYZus{}classif}\PY{p}{]}\PY{p}{,} \PY{c+c1}{\PYZsh{} F\PYZhy{}value statistic and Information Gain (entropy)}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{entropy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{c+c1}{\PYZsh{} \PYZhy{} Entropy is better than GINI from previous results}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{k+kc}{None}\PY{p}{]} \PY{o}{+} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}4\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}4}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{dt\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{p}{,}\PY{n}{target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{84}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{select\PYZus{}k\PYZus{}best} \PY{o}{=} \PY{n}{dt\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{attributes\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{attribute\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{get\PYZus{}support}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{scores\PYZus{}}\PY{p}{[}\PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{get\PYZus{}support}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{attributes\PYZus{}df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{attribute\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{kind}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{barh}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{logx}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Attributes: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{attributes\PYZus{}df}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Number of Attributes: 10
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{project_with_report_files/project_with_report_167_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Comment:} The analysis above shows that F-statistic proved to be
the method that makes the accuracy of the model higher
(\texttt{94.90\%}). This is an improvement, but not as `good' as the
improvement experienced with F-statistic. However, for exploratory,
examining the attributes there are differences in the attributes
prioritised by information gain and F-statistic.

    \hypertarget{attribute-reduction---support-vector-machine-with-select-k-best}{%
\subsubsection{Attribute Reduction - Support Vector Machine with Select
K-Best}\label{attribute-reduction---support-vector-machine-with-select-k-best}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{85}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svm\PYZus{}pipeline\PYZus{}4} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}  
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{select\PYZus{}kbest}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SelectKBest}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{svm\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{SVC}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Grid Search}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{select\PYZus{}kbest\PYZus{}\PYZus{}k}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{18}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{select\PYZus{}kbest\PYZus{}\PYZus{}score\PYZus{}func}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{n}{f\PYZus{}classif}\PY{p}{,}\PY{n}{mutual\PYZus{}info\PYZus{}classif}\PY{p}{]}\PY{p}{,} \PY{c+c1}{\PYZsh{} F\PYZhy{}value statistic and Information Gain (entropy)}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{svm\PYZus{}classifier\PYZus{}\PYZus{}kernel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{c+c1}{\PYZsh{} removed other attributes that seems to be inaccurate}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svm\PYZus{}pipeline\PYZus{}4\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{svm\PYZus{}pipeline\PYZus{}4}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{svm\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{p}{,}\PY{n}{target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{87}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{show\PYZus{}top\PYZus{}results}\PY{p}{(}\PY{n}{svm\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rrrl@{}}
\toprule
\begin{minipage}[b]{0.02\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedleft
rank\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedleft
mean\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.67\columnwidth}\raggedright
params\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
0\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedleft
0.9915\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
\{'select\_kbest\_\_k': 10, 'select\_kbest\_\_score\_func':
\textless function f\_classif at 0x0000027B4261E5E0\textgreater,
'svm\_classifier\_\_kernel': `linear'\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
4\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedleft
0.9915\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
\{'select\_kbest\_\_k': 11, 'select\_kbest\_\_score\_func':
\textless function f\_classif at 0x0000027B4261E5E0\textgreater,
'svm\_classifier\_\_kernel': `linear'\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
12\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedleft
3\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedleft
0.991\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
\{'select\_kbest\_\_k': 13, 'select\_kbest\_\_score\_func':
\textless function f\_classif at 0x0000027B4261E5E0\textgreater,
'svm\_classifier\_\_kernel': `linear'\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
8\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedleft
4\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedleft
0.9905\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
\{'select\_kbest\_\_k': 12, 'select\_kbest\_\_score\_func':
\textless function f\_classif at 0x0000027B4261E5E0\textgreater,
'svm\_classifier\_\_kernel': `linear'\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.02\columnwidth}\raggedleft
16\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedleft
4\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedleft
0.9905\strut
\end{minipage} & \begin{minipage}[t]{0.67\columnwidth}\raggedright
\{'select\_kbest\_\_k': 14, 'select\_kbest\_\_score\_func':
\textless function f\_classif at 0x0000027B4261E5E0\textgreater,
'svm\_classifier\_\_kernel': `linear'\}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Test Scores: }\PY{l+s+si}{\PYZob{}}\PY{n}{svm\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Params: }\PY{l+s+si}{\PYZob{}}\PY{n}{svm\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best CV Index: }\PY{l+s+si}{\PYZob{}}\PY{n}{svm\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}index\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{89}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{select\PYZus{}k\PYZus{}best} \PY{o}{=} \PY{n}{svm\PYZus{}pipeline\PYZus{}4\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
\PY{n}{attributes\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{attribute\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{get\PYZus{}support}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{scores\PYZus{}}\PY{p}{[}\PY{n}{select\PYZus{}k\PYZus{}best}\PY{o}{.}\PY{n}{get\PYZus{}support}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{attributes\PYZus{}df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{attribute\PYZus{}name}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{kind}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{barh}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{logx}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Number of Attributes: }\PY{l+s+si}{\PYZob{}}\PY{n+nb}{len}\PY{p}{(}\PY{n}{attributes\PYZus{}df}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Number of Attributes: 10
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{project_with_report_files/project_with_report_174_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{Comment:} The output (above) indicates a minor accuracy
improvement, from \texttt{98.95\%} to \texttt{99.1\%}. Note that this
increase is \texttt{0.04\%} better than the observed accuracy for SVM,
with PCA.

We also observe that the suggested best number of attributes (for SVM)
from F-statistic is \texttt{10}, a notably smaller value than the
suggested `best number' of attributes from F-statistic for Decision Tree
(\texttt{15}).

    \hypertarget{data-reduction---conclusion}{%
\subsection{Data Reduction -
Conclusion}\label{data-reduction---conclusion}}

As seen in our experiments above (with our chosen measure of
\emph{classifier-accuracy} as accuracy), numerosity reduction
\textbf{heavily} decreases the required data, in exchange for a small
decrease in overall model accuracy. Attribute reduction via
transformation (such as PCA) is seen in varying instances to both
increase / decrease the model accuracy, while attribute reduction (by
selection) demonstrated an overall net increase in accuracy .
Furthermore, with attribute reduction, we also observed a decrease in
required model-training time.

    \hypertarget{attribute-selection---manual-selection}{%
\subsection{Attribute Selection - Manual
Selection}\label{attribute-selection---manual-selection}}

With user-side specific domain knowledge (regarding expensive phones),
we manually selected the following attributes. Note that the accuracy of
this ``model'' is heavily dependent on the depth of the user's domain
specific knowledge. In most real-world data science projects, manual
attribute selection (performed by subject matter experts), mitigates the
possibility of over-fitting, that arises with pure criterium-based
attribute selection.

For example, in electrical-engineering problems (where the voltage
attribute is crucial) the data may suggest that voltage could/should be
eliminated (for the purpose of increasing accuracy). If relied upon, the
resultant model has the `best' accuracy, but it may inappropriate and/or
unusable in the real world.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{90}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Based on domain\PYZhy{}specific knowledge and the exploratory plots}
\PY{n}{MANUALLY\PYZus{}SELECTED\PYZus{}ATTRIBUTES} \PY{o}{=} \PY{p}{[}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ram}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{has\PYZus{}four\PYZus{}g}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mobile\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}width}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{screen\PYZus{}height}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{primary\PYZus{}cam\PYZus{}resolution}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{number\PYZus{}of\PYZus{}cores}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{int\PYZus{}memory}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{px\PYZus{}width}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{px\PYZus{}height}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

\PY{n}{feature\PYZus{}data\PYZus{}manually\PYZus{}selected} \PY{o}{=} \PY{n}{learning\PYZus{}data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{is\PYZus{}expensive}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{columns}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{[}\PY{n}{MANUALLY\PYZus{}SELECTED\PYZus{}ATTRIBUTES}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{decision-tree-with-manually-selected-attribute}{%
\subsection{Decision Tree with Manually Selected
Attribute}\label{decision-tree-with-manually-selected-attribute}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}1} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{dt\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{n}{RANDOM\PYZus{}STATE}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Grid Search}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{entropy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dt\PYZus{}classifier\PYZus{}\PYZus{}max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{k+kc}{None}\PY{p}{]} \PY{o}{+} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{feature\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}1}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{feature\PYZus{}data\PYZus{}manually\PYZus{}selected}\PY{p}{,}\PY{n}{target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{93}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{show\PYZus{}top\PYZus{}results}\PY{p}{(}\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rrrl@{}}
\toprule
\begin{minipage}[b]{0.03\columnwidth}\raggedleft
\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\raggedleft
rank\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.15\columnwidth}\raggedleft
mean\_test\_score\strut
\end{minipage} & \begin{minipage}[b]{0.56\columnwidth}\raggedright
params\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
4\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
0.9235\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `gini', 'dt\_classifier\_\_max\_depth':
4\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
0.9215\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `gini', 'dt\_classifier\_\_max\_depth':
2\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
1\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
2\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
0.9215\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `gini', 'dt\_classifier\_\_max\_depth':
1\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
3\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
4\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
0.9205\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `gini', 'dt\_classifier\_\_max\_depth':
3\}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.03\columnwidth}\raggedleft
25\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
5\strut
\end{minipage} & \begin{minipage}[t]{0.15\columnwidth}\raggedleft
0.9175\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\{'dt\_classifier\_\_criterion': `entropy',
'dt\_classifier\_\_max\_depth': 5\}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Test Scores: }\PY{l+s+si}{\PYZob{}}\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Params: }\PY{l+s+si}{\PYZob{}}\PY{n}{dt\PYZus{}pipeline\PYZus{}1\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \textbf{Comment:} When the Decision Tree was reduced with our
manually-selected-attribute model, we note a relatively large drop in
accuracy from \texttt{94.75\%} to \texttt{92.35\%} (\texttt{2.4\%}).

    \hypertarget{svm-with-manually-selected-attributes}{%
\subsection{SVM with Manually Selected
Attributes}\label{svm-with-manually-selected-attributes}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svm\PYZus{}pipeline\PYZus{}2} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{svm\PYZus{}classifier}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{SVC}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Grid Search}
\PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{svm\PYZus{}classifier\PYZus{}\PYZus{}kernel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{poly}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{svm\PYZus{}pipeline\PYZus{}2}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{CROSS\PYZus{}VALIDATION\PYZus{}PARTITION}\PY{p}{)}
\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{feature\PYZus{}data\PYZus{}manually\PYZus{}selected}\PY{p}{,}\PY{n}{target\PYZus{}data}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{97}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{show\PYZus{}top\PYZus{}results}\PY{p}{(}\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{longtable}[]{@{}rrrl@{}}
\toprule
& rank\_test\_score & mean\_test\_score & params\tabularnewline
\midrule
\endhead
2 & 1 & 0.9295 & \{'svm\_classifier\_\_kernel': `rbf'\}\tabularnewline
0 & 2 & 0.9265 & \{'svm\_classifier\_\_kernel':
`linear'\}\tabularnewline
1 & 2 & 0.9265 & \{'svm\_classifier\_\_kernel': `poly'\}\tabularnewline
3 & 4 & 0.519 & \{'svm\_classifier\_\_kernel':
`sigmoid'\}\tabularnewline
\bottomrule
\end{longtable}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Test Scores: }\PY{l+s+si}{\PYZob{}}\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Params: }\PY{l+s+si}{\PYZob{}}\PY{n}{svm\PYZus{}pipeline\PYZus{}2\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \textbf{Comment:} When the SVM was reduced with our
manually-selected-attribute model, we observe a notably large drop in
accuracy from \texttt{98.95\%} to \texttt{92.95\%}. This decrease in
accuracy with SVM (\texttt{6.0\%}) is much larger than the decrease
experienced by Decision Tree.

    \hypertarget{attribute-selection---conclusion}{%
\subsection{Attribute Selection -
Conclusion}\label{attribute-selection---conclusion}}

Through our experiments, F-statistic attribute selection demonstrated
the best overall accuracy for both SVM and Decision Tree, as defined by
the hyperparameter grid search.

Our results would indicate that Information Gain ranks second in
accuracy, increasing both SVM and DT's accuracy. This can be contrasted
with manual attribute selection, which showed poor results, with
decreases in the accuracy of \textbf{both} of our classifiers.

    \hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

    \hypertarget{raw-data-profiling-report}{%
\paragraph{Raw Data Profiling Report}\label{raw-data-profiling-report}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{raw\PYZus{}profile} \PY{o}{=} \PY{n}{ProfileReport}\PY{p}{(}\PY{n}{raw\PYZus{}data}\PY{p}{,} \PY{n}{explorative}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{orange\PYZus{}mode}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Raw Data Profiling Report}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} set the Metadata}
\PY{n}{metadata\PYZus{}dict} \PY{o}{=} \PY{n}{raw\PYZus{}metadata}\PY{o}{.}\PY{n}{to\PYZus{}dict}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Explaination}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

\PY{n}{raw\PYZus{}profile}\PY{o}{.}\PY{n}{set\PYZus{}variable}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{variables.descriptions}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{metadata\PYZus{}dict}\PY{p}{)}
\PY{n}{raw\PYZus{}profile}\PY{o}{.}\PY{n}{to\PYZus{}file}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./profile\PYZus{}reports/raw\PYZus{}data\PYZus{}profile.html}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{} raw\PYZus{}profile}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{clean-data-profiling-report}{%
\paragraph{Clean Data Profiling
Report}\label{clean-data-profiling-report}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Generate new pandas\PYZhy{}profiling }
\PY{n}{cleaned\PYZus{}data\PYZus{}profile} \PY{o}{=} \PY{n}{ProfileReport}\PY{p}{(}\PY{n}{cleaned\PYZus{}data}\PY{p}{,} \PY{n}{explorative}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{orange\PYZus{}mode}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Clean Data Profiling Report}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{cleaned\PYZus{}data\PYZus{}profile}\PY{o}{.}\PY{n}{set\PYZus{}variable}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{variables.descriptions}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{cleaned\PYZus{}metadata\PYZus{}dict}\PY{p}{)} \PY{c+c1}{\PYZsh{} Set Metadata                  }
\PY{n}{cleaned\PYZus{}data\PYZus{}profile}\PY{o}{.}\PY{n}{to\PYZus{}file}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./profile\PYZus{}reports/cleaned\PYZus{}data\PYZus{}profile.html}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{} cleaned\PYZus{}data\PYZus{}profile}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{discretised-data-profiling-report}{%
\paragraph{Discretised Data Profiling
Report}\label{discretised-data-profiling-report}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Generate new pandas\PYZhy{}profiling }
\PY{n}{discretised\PYZus{}data\PYZus{}profile} \PY{o}{=} \PY{n}{ProfileReport}\PY{p}{(}\PY{n}{discretised\PYZus{}data}\PY{p}{,} \PY{n}{explorative}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{orange\PYZus{}mode}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Discretised Data Profiling Report}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{discretised\PYZus{}data\PYZus{}profile}\PY{o}{.}\PY{n}{set\PYZus{}variable}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{variables.descriptions}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{cleaned\PYZus{}metadata\PYZus{}dict}\PY{p}{)} \PY{c+c1}{\PYZsh{} Set Metadata                  }
\PY{n}{discretised\PYZus{}data\PYZus{}profile}\PY{o}{.}\PY{n}{to\PYZus{}file}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{./profile\PYZus{}reports/discretised\PYZus{}data\PYZus{}profile.html}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{c+c1}{\PYZsh{} discretised\PYZus{}data\PYZus{}profile}
\end{Verbatim}
\end{tcolorbox}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
